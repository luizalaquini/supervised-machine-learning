{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UNIVERSIDADE DE SÃO PAULO**<br>\n",
    "**MBA DATA SCIENCE & ANALYTICS USP/ESALQ**<br>\n",
    "**SUPERVISED MACHINE LEARNING: ANÁLISE DE REGRESSÃO SIMPLES E MÚLTIPLA**<br>\n",
    "**Prof. Dr. Luiz Paulo Fávero**<br>\n",
    "Aluna: Luiza Batista Laquini<br>\n",
    "Turma: DSA 241<br>\n",
    "\n",
    "\n",
    "*coding: utf-8*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[0.1]: Instalação dos pacotes\n",
    "\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install -U seaborn\n",
    "# !pip install matplotlib\n",
    "# !pip install plotly\n",
    "# !pip install scipy\n",
    "# !pip install statsmodels\n",
    "# !pip install scikit-learn\n",
    "# !pip install playsound\n",
    "# !pip install pingouin\n",
    "# !pip install emojis\n",
    "# !pip install statstests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[0.2]: Importação dos pacotes\n",
    "\n",
    "import pandas as pd # manipulação de dados em formato de dataframe\n",
    "import numpy as np # operações matemáticas\n",
    "import seaborn as sns # visualização gráfica\n",
    "import matplotlib.pyplot as plt # visualização gráfica\n",
    "import plotly.graph_objects as go # gráficos 3D\n",
    "from scipy.stats import pearsonr # correlações de Pearson\n",
    "import statsmodels.api as sm # estimação de modelos\n",
    "from statsmodels.iolib.summary2 import summary_col # comparação entre modelos\n",
    "from sklearn.preprocessing import LabelEncoder # transformação de dados\n",
    "#from playsound import playsound # reprodução de sons => não foi possível instalar para o Python 3.12\n",
    "import pingouin as pg # outro modo para obtenção de matrizes de correlações\n",
    "import emojis # inserção de emojis em gráficos\n",
    "from statstests.process import stepwise # procedimento Stepwise\n",
    "from statstests.tests import shapiro_francia # teste de Shapiro-Francia\n",
    "from scipy.stats import boxcox # transformação de Box-Cox\n",
    "from scipy.stats import norm # para plotagem da curva normal\n",
    "from scipy import stats # utilizado na definição da função 'breusch_pagan_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tempodist.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# In[EXEMPLO 1]:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#############################################################################\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#                          REGRESSÃO LINEAR SIMPLES                         #\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#                  EXEMPLO 1 - CARREGAMENTO DA BASE DE DADOS                #\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#############################################################################\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df_tempodist \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtempodist.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m df_tempodist\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Características das variáveis do dataset\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\madeinweb\\Documents\\GitHub\\supervised-machine-learning\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\madeinweb\\Documents\\GitHub\\supervised-machine-learning\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\madeinweb\\Documents\\GitHub\\supervised-machine-learning\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\madeinweb\\Documents\\GitHub\\supervised-machine-learning\\myenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\madeinweb\\Documents\\GitHub\\supervised-machine-learning\\myenv\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tempodist.csv'"
     ]
    }
   ],
   "source": [
    "# In[EXEMPLO 1]:\n",
    "#############################################################################\n",
    "#                          REGRESSÃO LINEAR SIMPLES                         #\n",
    "#                  EXEMPLO 1 - CARREGAMENTO DA BASE DE DADOS                #\n",
    "#############################################################################\n",
    "    \n",
    "df_tempodist = pd.read_csv('Regretempodist.csv', delimiter=',')\n",
    "df_tempodist\n",
    "\n",
    "# Características das variáveis do dataset\n",
    "df_tempodist.info()\n",
    "\n",
    "# Estatísticas univariadas\n",
    "df_tempodist.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1.1]: Gráfico de dispersão com o ajuste linear (fitted values de um modelo\n",
    "#de regressão) que se adequa às observações: função 'regplot' do pacote 'seaborn'\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(data=df_tempodist, x='distancia', y='tempo', marker='o', ci=False,\n",
    "            scatter_kws={\"color\":'navy', 'alpha':0.9, 's':220},\n",
    "            line_kws={\"color\":'grey', 'linewidth': 5})\n",
    "plt.title('Valores Reais e Fitted Values (Modelo de Regressão)', fontsize=30)\n",
    "plt.xlabel('Distância', fontsize=24)\n",
    "plt.ylabel('Tempo', fontsize=24)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlim(0, 35)\n",
    "plt.ylim(0, 60)\n",
    "plt.legend(['Valores Reais', 'Fitted Values'], fontsize=24, loc='upper left')\n",
    "plt.show\n",
    "\n",
    "# In[1.2]: Gráfico de dispersão interativo (figura 'EXEMPLO1.html' salva na\n",
    "#pasta do curso)\n",
    "\n",
    "# Dados do gráfico\n",
    "x = df_tempodist['distancia']\n",
    "y = df_tempodist['tempo']\n",
    "\n",
    "# Definição da regressão linear\n",
    "slope, intercept = np.polyfit(x, y, 1)\n",
    "y_trend = slope * x + intercept\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Inserção dos pontos (valores reais)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    mode='markers',\n",
    "    marker=dict(color='navy', size=20), name='Valores Reais')\n",
    "    )\n",
    "\n",
    "# Inserção da reta (fitted values)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x,\n",
    "    y=y_trend,\n",
    "    mode='lines',\n",
    "    line=dict(color='dimgray', width=5), name='Fitted Values')\n",
    "    )\n",
    "\n",
    "# Configurações de layout\n",
    "fig.update_layout(\n",
    "    xaxis_title='Distância',\n",
    "    yaxis_title='Tempo',\n",
    "    title={\n",
    "        'text': 'Gráfico de Dispersão com Fitted Values',\n",
    "        'font': {'size': 20, 'color': 'black', 'family': 'Arial'},\n",
    "        'x': 0.5,\n",
    "        'y': 0.97,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'\n",
    "    },\n",
    "    plot_bgcolor='snow',\n",
    "    xaxis=dict(gridcolor='black'),\n",
    "    yaxis=dict(gridcolor='black'),\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.write_html('EXEMPLO1.html')\n",
    "\n",
    "# Abrir o arquivo HTML no navegador\n",
    "import webbrowser\n",
    "webbrowser.open('EXEMPLO1.html')\n",
    "\n",
    "# In[1.3]: Estimação do modelo de regressão linear simples\n",
    "\n",
    "# Estimação do modelo\n",
    "modelo = sm.OLS.from_formula('tempo ~ distancia', df_tempodist).fit()\n",
    "\n",
    "# Observação dos parâmetros resultantes da estimação\n",
    "modelo.summary()\n",
    "\n",
    "# In[1.4]: Salvando fitted values (variável yhat) e residuals (variável erro)\n",
    "#no dataset\n",
    "\n",
    "df_tempodist['yhat'] = modelo.fittedvalues\n",
    "df_tempodist['erro'] = modelo.resid\n",
    "df_tempodist\n",
    "\n",
    "# In[1.5]: Gráfico didático para visualizar o conceito de R²\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "y = df_tempodist['tempo']\n",
    "yhat = df_tempodist['yhat']\n",
    "x = df_tempodist['distancia']\n",
    "mean = np.full(x.shape[0] , y.mean(), dtype=int)\n",
    "\n",
    "for i in range(len(x)-1):\n",
    "    plt.plot(x, yhat, color='grey', linewidth=7)\n",
    "    plt.plot([x[i], x[i]], [yhat[i], mean[i]], '--', color='darkorchid', linewidth=5)\n",
    "    plt.plot([x[i], x[i]], [yhat[i], y[i]],':', color='limegreen', linewidth=5)\n",
    "    plt.scatter(x, y, color='navy', s=220, alpha=0.2)\n",
    "    plt.axhline(y = y.mean(), color = 'silver', linestyle = '-', linewidth=4)\n",
    "    plt.title('R²: ' + str(round(modelo.rsquared, 4)), fontsize=30)\n",
    "    plt.xlabel('Distância', fontsize=24)\n",
    "    plt.ylabel('Tempo', fontsize=24)\n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    plt.xlim(0, 35)\n",
    "    plt.ylim(0, 60)\n",
    "    plt.legend(['Fitted Values', 'Ychapéu - Ymédio', 'Erro = Y - Ychapéu'],\n",
    "               fontsize=22, loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# In[1.6]: Cálculo manual do R²\n",
    "\n",
    "R2 = ((df_tempodist['yhat']-\n",
    "       df_tempodist['tempo'].mean())**2).sum()/(((df_tempodist['yhat']-\n",
    "                                        df_tempodist['tempo'].mean())**2).sum()+\n",
    "                                        (df_tempodist['erro']**2).sum())\n",
    "\n",
    "round(R2,4)\n",
    "\n",
    "# In[1.7]: Coeficiente de ajuste (R²) é a correlação ao quadrado\n",
    "\n",
    "# Correlação de Pearson\n",
    "df_tempodist[['tempo','distancia']].corr()\n",
    "\n",
    "# R²\n",
    "(df_tempodist[['tempo','distancia']].corr())**2\n",
    "\n",
    "# R² de maneira direta\n",
    "modelo.rsquared\n",
    "\n",
    "# In[1.8]: Modelo auxiliar para mostrar R² igual a 100% (para fins didáticos)\n",
    "\n",
    "# Estimação do modelo com yhat como variável dependente resultará em um modelo\n",
    "#com R² igual a 100%\n",
    "modelo_auxiliar = sm.OLS.from_formula('yhat ~ distancia', df_tempodist).fit()\n",
    "\n",
    "# Parâmetros resultantes da estimação deste modelo didático\n",
    "modelo_auxiliar.summary()\n",
    "\n",
    "# In[1.9]:Gráfico mostrando o perfect fit\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(data=df_tempodist, x='distancia', y='yhat',\n",
    "                color='navy', alpha=0.9, s=300)\n",
    "sns.regplot(data=df_tempodist, x='distancia', y='yhat', ci=False, scatter=False,\n",
    "            label='Fitted Values',\n",
    "            line_kws={\"color\":'grey', 'linewidth': 5})\n",
    "plt.title('Perfect Fit', fontsize=30)\n",
    "plt.xlabel('Distância', fontsize=24)\n",
    "plt.ylabel('Tempo', fontsize=24)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlim(0, 35)\n",
    "plt.ylim(0, 60)\n",
    "plt.legend(loc='upper left', fontsize=24)\n",
    "plt.show\n",
    "\n",
    "# In[1.10]:Gráfico mostrando o perfect fit com figura .JPG e som .MP3\n",
    "\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Define a URL da imagem (FONTE: Divulgação/Warner Bros. Pictures)\n",
    "url = \"https://cinebuzz.uol.com.br/media/uploads/harry_potter_3_WumwIEd.jpg\"\n",
    "\n",
    "# Define os cabeçalhos da solicitação\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "\n",
    "# Cria uma solicitação com os cabeçalhos\n",
    "request = urllib.request.Request(url, headers=headers)\n",
    "\n",
    "# Abre a URL e lê os dados da imagem\n",
    "response = urllib.request.urlopen(request)\n",
    "image_data = response.read()\n",
    "\n",
    "# Carrega a imagem em um objeto PIL (Python Imaging Library)\n",
    "imagem = Image.open(BytesIO(image_data))\n",
    "\n",
    "# Define as dimensões e a posição desejada da imagem\n",
    "nova_largura = 8400  # Largura da imagem redimensionada\n",
    "nova_altura = 5430  # Altura da imagem redimensionada\n",
    "posicao_x = 630  # Posição horizontal da imagem\n",
    "posicao_y = 600  # Posição vertical da imagem\n",
    "\n",
    "# Redimensiona a imagem\n",
    "imagem_redimensionada = imagem.resize((nova_largura, nova_altura))\n",
    "\n",
    "# Cria o gráfico por meio da função 'regplot' do pacote 'seaborn'\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(data=df_tempodist, x='distancia', y='yhat',\n",
    "                color='navy', alpha=0.9, s=300)\n",
    "sns.regplot(data=df_tempodist, x='distancia', y='yhat', ci=False, scatter=False,\n",
    "            label='Fitted Values',\n",
    "            line_kws={\"color\":'grey', 'linewidth': 5})\n",
    "plt.title('Perfect Fit', fontsize=30)\n",
    "plt.xlabel('Distância', fontsize=24)\n",
    "plt.ylabel('Tempo', fontsize=24)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlim(0, 35)\n",
    "plt.ylim(0, 60)\n",
    "plt.legend(loc='upper left', fontsize=24)\n",
    "plt.show\n",
    "\n",
    "# Adiciona a imagem redimensionada em uma posição específica do gráfico\n",
    "plt.figimage(imagem_redimensionada, posicao_x, posicao_y, zorder=1, alpha=0.20)\n",
    "\n",
    "# Exibe o gráfico com a imagem\n",
    "plt.show()\n",
    "\n",
    "# Reproduz um som padrão (arquivo na pasta do curso)\n",
    "# Aqui você deve colocar a URL da pasta em que se encontra o arquivo 'sound.mp3',\n",
    "#com duas barras!\n",
    "playsound('C:\\\\MBA DSA USP Esalq\\\\Análise de Regressão Simples e Múltipla\\\\sound.mp3')\n",
    "\n",
    "# In[1.11]: Voltando ao nosso modelo original\n",
    "\n",
    "# Gráfico com intervalo de confiança de 90%\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(data=df_tempodist, x='distancia', y='tempo', marker='o', ci=90,\n",
    "            scatter_kws={\"color\":'navy', 'alpha':0.7, 's':220},\n",
    "            line_kws={\"color\":'grey', 'linewidth': 5})\n",
    "plt.title('IC: 90%', fontsize=30)\n",
    "plt.xlabel('Distância', fontsize=24)\n",
    "plt.ylabel('Tempo', fontsize=24)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlim(0, 35)\n",
    "plt.ylim(0, 60)\n",
    "plt.legend(['Valores Reais', 'Fitted Values', '90% IC'],\n",
    "           fontsize=24, loc='upper left')\n",
    "plt.show\n",
    "\n",
    "# In[1.12]: Gráfico com intervalo de confiança de 95%\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(data=df_tempodist, x='distancia', y='tempo', marker='o', ci=95,\n",
    "            scatter_kws={\"color\":'navy', 'alpha':0.7, 's':220},\n",
    "            line_kws={\"color\":'grey', 'linewidth': 5})\n",
    "plt.title('IC: 95%', fontsize=30)\n",
    "plt.xlabel('Distância', fontsize=24)\n",
    "plt.ylabel('Tempo', fontsize=24)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlim(0, 35)\n",
    "plt.ylim(0, 60)\n",
    "plt.legend(['Valores Reais', 'Fitted Values', '95% IC'],\n",
    "           fontsize=24, loc='upper left')\n",
    "plt.show\n",
    "\n",
    "# In[1.13]: Gráfico com intervalo de confiança de 99%\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(data=df_tempodist, x='distancia', y='tempo', marker='o', ci=99,\n",
    "            scatter_kws={\"color\":'navy', 'alpha':0.7, 's':220},\n",
    "            line_kws={\"color\":'grey', 'linewidth': 5})\n",
    "plt.title('IC: 99%', fontsize=30)\n",
    "plt.xlabel('Distância', fontsize=24)\n",
    "plt.ylabel('Tempo', fontsize=24)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlim(0, 35)\n",
    "plt.ylim(0, 60)\n",
    "plt.legend(['Valores Reais', 'Fitted Values', '99% IC'],\n",
    "           fontsize=24, loc='upper left')\n",
    "plt.show\n",
    "\n",
    "# In[1.14]: Gráfico com intervalo de confiança de 99,99999%\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(data=df_tempodist, x='distancia', y='tempo', marker='o', ci=99.99999,\n",
    "            scatter_kws={\"color\":'navy', 'alpha':0.7, 's':220},\n",
    "            line_kws={\"color\":'grey', 'linewidth': 5})\n",
    "plt.title('IC: 99,99999%', fontsize=30)\n",
    "plt.xlabel('Distância', fontsize=24)\n",
    "plt.ylabel('Tempo', fontsize=24)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlim(0, 35)\n",
    "plt.ylim(0, 60)\n",
    "plt.legend(['Valores Reais', 'Fitted Values', '99,99999% IC'],\n",
    "           fontsize=24, loc='upper left')\n",
    "plt.show\n",
    "\n",
    "# In[1.15]: Calculando os intervalos de confiança\n",
    "\n",
    "# Nível de significância de 10% / Nível de confiança de 90%\n",
    "modelo.conf_int(alpha=0.1)\n",
    "\n",
    "# Nível de significância de 5% / Nível de confiança de 95%\n",
    "modelo.conf_int(alpha=0.05)\n",
    "\n",
    "# Nível de significância de 1% / Nível de confiança de 99%\n",
    "modelo.conf_int(alpha=0.01)\n",
    "\n",
    "# Nível de significância de 0,00001% / Nível de confiança de 99,99999%\n",
    "modelo.conf_int(alpha=0.0000001)\n",
    "\n",
    "# In[1.16]: Fazendo predições em modelos OLS\n",
    "# Ex.: Qual seria o tempo gasto, em média, para percorrer a distância de 25km?\n",
    "\n",
    "# Cálculo manual\n",
    "5.8784 + 1.4189*(25)\n",
    "\n",
    "# Cálculo utilizando os próprios parâmetros estimados do modelo\n",
    "modelo.params[0] + modelo.params[1]*(25)\n",
    "\n",
    "# Maneira direta utilizando a função 'DataFrame' do pacote 'pandas' dentro\n",
    "#da função 'predict'\n",
    "modelo.predict(pd.DataFrame({'distancia':[25]}))\n",
    "\n",
    "# In[1.17]: Nova modelagem para o mesmo exemplo, com novo dataset que\n",
    "#contém replicações\n",
    "\n",
    "# Quantas replicações de cada linha você quer? -> função 'repeat' do 'numpy'\n",
    "df_replicado = pd.DataFrame(np.repeat(df_tempodist.values, 3, axis=0))\n",
    "df_replicado.columns = df_tempodist.columns\n",
    "df_replicado\n",
    "\n",
    "# In[1.18]: Estimação do modelo com valores replicados\n",
    "\n",
    "modelo_replicado = sm.OLS.from_formula('tempo ~ distancia',\n",
    "                                       df_replicado).fit()\n",
    "\n",
    "# Parâmetros do 'modelo_replicado'\n",
    "modelo_replicado.summary()\n",
    "\n",
    "# In[1.19]: Calculando os novos intervalos de confiança\n",
    "\n",
    "# Nível de significância de 5% / Nível de confiança de 95%\n",
    "modelo_replicado.conf_int(alpha=0.05)\n",
    "\n",
    "# In[1.20]: Plotando o novo gráfico com intervalo de confiança de 95%\n",
    "# Note o estreitamento da amplitude dos intervalos de confiança!\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(data=df_replicado, x='distancia', y='tempo', marker='o', ci=95,\n",
    "            scatter_kws={\"color\":'navy', 'alpha':0.7, 's':220},\n",
    "            line_kws={\"color\":'grey', 'linewidth': 5})\n",
    "plt.title('IC: 95%', fontsize=30)\n",
    "plt.xlabel('Distância', fontsize=24)\n",
    "plt.ylabel('Tempo', fontsize=24)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xlim(0, 35)\n",
    "plt.ylim(0, 60)\n",
    "plt.legend(['Valores Reais', 'Fitted Values', '95% IC'],\n",
    "           fontsize=24, loc='upper left')\n",
    "plt.show\n",
    "\n",
    "# In[1.21]: PROCEDIMENTO ERRADO: ELIMINAR O INTERCEPTO QUANDO ESTE NÃO SE\n",
    "#MOSTRAR ESTATISTICAMENTE SIGNIFICANTE\n",
    "\n",
    "modelo_errado = sm.OLS.from_formula('tempo ~ 0 + distancia', df_tempodist).fit()\n",
    "\n",
    "# Parâmetros do 'modelo_errado'\n",
    "modelo_errado.summary()\n",
    "\n",
    "# In[1.22]: Comparando os parâmetros do modelo inicial (objeto 'modelo')\n",
    "#com o 'modelo_errado' pela função 'summary_col' do pacote\n",
    "#'statsmodels.iolib.summary2'\n",
    "\n",
    "summary_col([modelo, modelo_errado])\n",
    "\n",
    "# Outro modo mais completo também pela função 'summary_col'\n",
    "summary_col([modelo, modelo_errado],\n",
    "            model_names=[\"MODELO INICIAL\",\"MODELO ERRADO\"],\n",
    "            stars=True,\n",
    "            info_dict = {\n",
    "                'N':lambda x: \"{0:d}\".format(int(x.nobs))\n",
    "        })\n",
    "\n",
    "# In[1.23]: Gráfico didático para visualizar o viés decorrente de se eliminar\n",
    "#erroneamente o intercepto em modelos regressivos\n",
    "\n",
    "x = df_tempodist['distancia']\n",
    "y = df_tempodist['tempo']\n",
    "\n",
    "yhat = df_tempodist['yhat']\n",
    "yhat_errado = modelo_errado.fittedvalues\n",
    "\n",
    "plt.plot(x, y, 'o', color='navy')\n",
    "plt.plot(x, yhat, color='gray')\n",
    "plt.plot(x, yhat_errado, color='red')\n",
    "plt.xlabel(\"Distância\")\n",
    "plt.ylabel(\"Tempo\")\n",
    "plt.xlim(0, 35)\n",
    "plt.ylim(0, 60)\n",
    "plt.legend(['Valores Observados','Fitted Values OLS',\n",
    "            'Sem Intercepto'], fontsize=9)\n",
    "plt.show()\n",
    "\n",
    "# In[1.24]: DÚVIDA: Qual estimação devo escolher? (com figura proveninente de URL)\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "# Definição da URL da imagem\n",
    "url = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQKNf7Jk3b2LG23egCN7w7TW0275Vd2_lhYWHLlGGizplLYc74wLukF-EbOIB8YY8YB9L0&usqp=CAU\"\n",
    "\n",
    "# Carregamento da imagem da URL\n",
    "imagem = Image.open(urllib.request.urlopen(url))\n",
    "\n",
    "# Definição das dimensões e da posição desejada da imagem\n",
    "nova_largura = 700  # Largura da imagem redimensionada\n",
    "nova_altura = 1000  # Altura da imagem redimensionada\n",
    "posicao_x = 2500  # Posição horizontal da imagem\n",
    "posicao_y = 400  # Posição vertical da imagem\n",
    "\n",
    "# Redimensionamento da imagem\n",
    "imagem_redimensionada = imagem.resize((nova_largura, nova_altura))\n",
    "\n",
    "# Construção do gráfico\n",
    "x = df_tempodist['distancia']\n",
    "y = df_tempodist['tempo']\n",
    "\n",
    "yhat = df_tempodist['yhat']\n",
    "yhat_errado = modelo_errado.fittedvalues\n",
    "\n",
    "plt.plot(x, y, 'o', color='navy')\n",
    "plt.plot(x, yhat, color='gray')\n",
    "plt.plot(x, yhat_errado, color='red')\n",
    "plt.xlabel(\"Distância\")\n",
    "plt.ylabel(\"Tempo\")\n",
    "plt.xlim(0, 35)\n",
    "plt.ylim(0, 60)\n",
    "plt.legend(['Valores Observados','Fitted Values OLS',\n",
    "            'Sem Intercepto'], fontsize=9)\n",
    "\n",
    "# Inserção da imagem redimensionada em uma posição específica no gráfico\n",
    "plt.figimage(imagem_redimensionada, posicao_x, posicao_y, zorder=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# In[1.25]: DECISÃO: DEVO ESCOLHER O MODELO COM INTERCEPTO!\n",
    "\n",
    "# Definição das URLs das imagems\n",
    "url1 = \"https://cdn-icons-png.flaticon.com/512/5290/5290081.png\"\n",
    "url2 = \"https://i.pinimg.com/originals/d3/82/6a/d3826a943b0d3a9d54ec3d3cba01d0ef.png\"\n",
    "\n",
    "# Carregamento das imagens das URLs\n",
    "imagem1 = Image.open(urllib.request.urlopen(url1))\n",
    "imagem2 = Image.open(urllib.request.urlopen(url2))\n",
    "\n",
    "# Definição das dimensões e das posições desejadas das imagens\n",
    "nova_largura1 = 600  # Largura da imagem 1 redimensionada\n",
    "nova_altura1 = 800  # Altura da imagem 1 redimensionada\n",
    "posicao_x1 = 1550  # Posição horizontal da imagem 1\n",
    "posicao_y1 = 1370  # Posição vertical da imagem 1\n",
    "\n",
    "nova_largura2 = 500  # Largura da imagem 2 redimensionada\n",
    "nova_altura2 = 500  # Altura da imagem 2 redimensionada\n",
    "posicao_x2 = 2000  # Posição horizontal da imagem 2\n",
    "posicao_y2 = 700  # Posição vertical da imagem 2\n",
    "\n",
    "# Redimensionamento das imagens\n",
    "imagem_redimensionada1 = imagem1.resize((nova_largura1, nova_altura1))\n",
    "imagem_redimensionada2 = imagem2.resize((nova_largura2, nova_altura2))\n",
    "\n",
    "# Construção do gráfico\n",
    "x = df_tempodist['distancia']\n",
    "y = df_tempodist['tempo']\n",
    "\n",
    "yhat = df_tempodist['yhat']\n",
    "yhat_errado = modelo_errado.fittedvalues\n",
    "\n",
    "plt.plot(x, y, 'o', color='navy')\n",
    "plt.plot(x, yhat, color='gray')\n",
    "plt.plot(x, yhat_errado, color='red')\n",
    "plt.xlabel(\"Distância\")\n",
    "plt.ylabel(\"Tempo\")\n",
    "plt.xlim(0, 35)\n",
    "plt.ylim(0, 60)\n",
    "plt.legend(['Valores Observados','Fitted Values OLS',\n",
    "            'Sem Intercepto'], fontsize=9)\n",
    "\n",
    "# Inserção das imagens redimensionadas em posições específicas no gráfico\n",
    "plt.figimage(imagem_redimensionada1, posicao_x1, posicao_y1, zorder=1)\n",
    "plt.figimage(imagem_redimensionada2, posicao_x2, posicao_y2, zorder=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[EXEMPLO 2]:\n",
    "#############################################################################\n",
    "#                         REGRESSÃO LINEAR MÚLTIPLA                         #\n",
    "#                 EXEMPLO 2 - CARREGAMENTO DA BASE DE DADOS                 #\n",
    "#############################################################################\n",
    "\n",
    "df_paises = pd.read_csv('paises.csv', delimiter=',', encoding=\"utf-8\")\n",
    "df_paises\n",
    "\n",
    "#Características das variáveis do dataset\n",
    "df_paises.info()\n",
    "\n",
    "#Estatísticas univariadas\n",
    "df_paises.describe()\n",
    "\n",
    "# In[2.1]: Gráfico 3D com scatter gerado em HTML e aberto no browser\n",
    "#(figura 'EXEMPLO2_scatter3D.html' salva na pasta do curso)\n",
    "\n",
    "trace = go.Scatter3d(\n",
    "    x=df_paises['horas'], \n",
    "    y=df_paises['idade'], \n",
    "    z=df_paises['cpi'], \n",
    "    mode='markers',\n",
    "    marker={\n",
    "        'size': 10,\n",
    "        'color': 'darkorchid',\n",
    "        'opacity': 0.7,\n",
    "    },\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
    "    width=800,\n",
    "    height=800,\n",
    "    plot_bgcolor='white',\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            gridcolor='rgb(200, 200, 200)',\n",
    "            backgroundcolor='whitesmoke'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            gridcolor='rgb(200, 200, 200)',\n",
    "            backgroundcolor='whitesmoke'\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            gridcolor='rgb(200, 200, 200)',\n",
    "            backgroundcolor='whitesmoke'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "plot_figure = go.Figure(data=data, layout=layout)\n",
    "plot_figure.update_layout(scene=dict(\n",
    "    xaxis_title='horas',\n",
    "    yaxis_title='idade',\n",
    "    zaxis_title='cpi'\n",
    "))\n",
    "\n",
    "plot_figure.write_html('EXEMPLO2_scatter3D.html')\n",
    "\n",
    "# Abre o arquivo HTML no browser\n",
    "import webbrowser\n",
    "webbrowser.open('EXEMPLO2_scatter3D.html')\n",
    "\n",
    "# In[2.2]: Matriz de correlações\n",
    "\n",
    "correlation_matrix = df_paises.iloc[:,1:4].corr()\n",
    "correlation_matrix\n",
    "\n",
    "# Mapa de calor com as correlações entre todas as variáveis quantitativas\n",
    "plt.figure(figsize=(15, 10))\n",
    "heatmap = sns.heatmap(correlation_matrix, annot=True, fmt=\".4f\",\n",
    "                      cmap=plt.cm.viridis_r,\n",
    "                      annot_kws={'size': 25}, vmin=-1, vmax=1)\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontsize=17)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontsize=17)\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=17)\n",
    "plt.show()\n",
    "\n",
    "# Paletas de cores ('_r' reverte a sequência de cores):\n",
    "# viridis\n",
    "# inferno\n",
    "# magma\n",
    "# cividis\n",
    "# coolwarm\n",
    "# Blues\n",
    "# Greens\n",
    "# Reds\n",
    "\n",
    "# In[2.3]: Diagrama interessante (grafo) que mostra a inter-relação entre as\n",
    "#variáveis e a magnitude das correlações entre elas\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Criação de um grafo direcionado\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Adição das variáveis como nós do grafo\n",
    "for variable in correlation_matrix.columns:\n",
    "    G.add_node(variable)\n",
    "\n",
    "# Adição das arestas com espessuras proporcionais às correlações\n",
    "for i, variable1 in enumerate(correlation_matrix.columns):\n",
    "    for j, variable2 in enumerate(correlation_matrix.columns):\n",
    "        if i != j:\n",
    "            correlation = correlation_matrix.iloc[i, j]\n",
    "            if abs(correlation) > 0:\n",
    "                G.add_edge(variable1, variable2, weight=correlation)\n",
    "\n",
    "# Obtenção da lista de correlações das arestas\n",
    "correlations = [d[\"weight\"] for _, _, d in G.edges(data=True)]\n",
    "\n",
    "# Definição da dimensão dos nós\n",
    "node_size = 2700\n",
    "\n",
    "# Definição da cor dos nós\n",
    "node_color = 'black'\n",
    "\n",
    "# Definição da escala de cores das retas (correspondência com as correlações)\n",
    "cmap = plt.colormaps.get_cmap('coolwarm_r')\n",
    "\n",
    "# Criação de uma lista de espessuras das arestas proporcional às correlações\n",
    "edge_widths = [abs(d[\"weight\"]) * 25 for _, _, d in G.edges(data=True)]\n",
    "\n",
    "# Criação do layout do grafo com maior distância entre os nós\n",
    "pos = nx.spring_layout(G, k=0.75)  # k para controlar a distância entre os nós\n",
    "\n",
    "# Desenho dos nós e das arestas com base nas correlações e espessuras\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_size, node_color=node_color)\n",
    "nx.draw_networkx_edges(G, pos, width=edge_widths, edge_color=correlations,\n",
    "                       edge_cmap=cmap, alpha=0.7)\n",
    "\n",
    "# Adição dos rótulos dos nós\n",
    "labels = {node: node for node in G.nodes}\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=10, font_color='white')\n",
    "\n",
    "# Ajuste dos limites dos eixos\n",
    "ax = plt.gca()\n",
    "ax.margins(0.1)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Criação da legenda com a escala de cores definida\n",
    "smp = cm.ScalarMappable(cmap=cmap)\n",
    "smp.set_array([min(correlations), max(correlations)])\n",
    "cbar = plt.colorbar(smp, ax=ax, label='Correlação')\n",
    "\n",
    "# Exibição do gráfico\n",
    "plt.show()\n",
    "\n",
    "# In[2.4]: Matriz de correlações mais elaborada, com uso da função 'rcorr' do\n",
    "#pacote 'pingouin'\n",
    "\n",
    "import pingouin as pg\n",
    "\n",
    "correlation_matrix2 = pg.rcorr(df_paises, method='pearson',\n",
    "                               upper='pval', decimals=6,\n",
    "                               pval_stars={0.01: '***',\n",
    "                                           0.05: '**',\n",
    "                                           0.10: '*'})\n",
    "correlation_matrix2\n",
    "\n",
    "# In[2.5]: Gráfico com distribuições das variáveis, scatters, valores das\n",
    "#correlações e respectivas significâncias estatísticas\n",
    "\n",
    "def corrfunc(x, y, **kws):\n",
    "    (r, p) = pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.3f}\".format(r),\n",
    "                xy=(.30, .9), xycoords=ax.transAxes, fontsize=14)\n",
    "    ax.annotate(\"p = {:.3f}\".format(p),\n",
    "                xy=(.30, .8), xycoords=ax.transAxes, fontsize=14)\n",
    "\n",
    "# Configuração do gráfico\n",
    "sns.set(style=\"whitegrid\", palette=\"viridis\")\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "graph = sns.pairplot(df_paises, diag_kind=\"kde\", plot_kws={\"color\": \"darkorchid\"},\n",
    "                     height=2.5, aspect=1.7)\n",
    "graph.map(corrfunc)\n",
    "for ax in graph.axes.flat:\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=14)\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# In[2.6]: Estimação de um modelo de regressão múltipla com as variáveis do\n",
    "#dataframe 'df_paises'\n",
    "\n",
    "# Estimando o modelo de regressão múltipla por OLS\n",
    "modelo_paises = sm.OLS.from_formula(\"cpi ~ idade + horas\", df_paises).fit()\n",
    "\n",
    "# Parâmetros do 'modelo_paises'\n",
    "modelo_paises.summary()\n",
    "\n",
    "# Cálculo do R² ajustado (slide 31 da apostila)\n",
    "r2_ajust = 1-((len(df_paises.index)-1)/(len(df_paises.index)-\\\n",
    "                                          modelo_paises.params.count()))*\\\n",
    "    (1-modelo_paises.rsquared)\n",
    "r2_ajust # modo direto: modelo_paises.rsquared_adj\n",
    "\n",
    "# In[2.7]: Salvando os fitted values na base de dados\n",
    "\n",
    "df_paises['cpifit'] = modelo_paises.fittedvalues\n",
    "df_paises\n",
    "\n",
    "# In[2.8]: Gráfico 3D com scatter e fitted values (superfície espacial)\n",
    "#resultantes do 'modelo_paises', gerado em HTML e aberto no browser\n",
    "#(figura 'EXEMPLO2_scatter3D_fitted.html' salva na pasta do curso)\n",
    "\n",
    "trace = go.Scatter3d(\n",
    "    x=df_paises['horas'], \n",
    "    y=df_paises['idade'], \n",
    "    z=df_paises['cpi'], \n",
    "    mode='markers',\n",
    "    marker={\n",
    "        'size': 10,\n",
    "        'color': 'darkorchid',\n",
    "        'opacity': 0.7,\n",
    "    },\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
    "    width=800,\n",
    "    height=800,\n",
    "    plot_bgcolor='white',\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            gridcolor='rgb(200, 200, 200)',\n",
    "            backgroundcolor='whitesmoke'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            gridcolor='rgb(200, 200, 200)',\n",
    "            backgroundcolor='whitesmoke'\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            gridcolor='rgb(200, 200, 200)',\n",
    "            backgroundcolor='whitesmoke'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "plot_figure = go.Figure(data=data, layout=layout)\n",
    "plot_figure.add_trace(go.Mesh3d(\n",
    "                    x=df_paises['horas'], \n",
    "                    y=df_paises['idade'], \n",
    "                    z=df_paises['cpifit'], \n",
    "                    opacity=0.5,\n",
    "                    color='orange'\n",
    "                  ))\n",
    "plot_figure.update_layout(scene = dict(\n",
    "                        xaxis_title='horas',\n",
    "                        yaxis_title='idade',\n",
    "                        zaxis_title='cpi'))\n",
    "\n",
    "plot_figure.write_html('EXEMPLO2_scatter3D_fitted.html')\n",
    "\n",
    "# Abre o arquivo HTML no browser\n",
    "import webbrowser\n",
    "webbrowser.open('EXEMPLO2_scatter3D_fitted.html')\n",
    "\n",
    "\n",
    "# In[EXEMPLO 3]:\n",
    "#############################################################################\n",
    "#         REGRESSÃO COM UMA VARIÁVEL EXPLICATIVA (X) QUALITATIVA            #\n",
    "#               EXEMPLO 3 - CARREGAMENTO DA BASE DE DADOS                   #\n",
    "#############################################################################\n",
    "\n",
    "df_corrupcao = pd.read_csv('corrupcao.csv',delimiter=',',encoding='utf-8')\n",
    "df_corrupcao\n",
    "\n",
    "# Características das variáveis do dataset\n",
    "df_corrupcao.info()\n",
    "\n",
    "# Estatísticas univariadas\n",
    "df_corrupcao.describe()\n",
    "\n",
    "# Estatísticas univariadas por região\n",
    "df_corrupcao.groupby('regiao').describe()\n",
    "\n",
    "# In[3.1]: Tabela de frequências da variável 'regiao'\n",
    "\n",
    "# Função 'value_counts' do pacote 'pandas' sem e com o argumento 'normalize'\n",
    "#para gerar, respectivamente, as contagens e os percentuais\n",
    "contagem = df_corrupcao['regiao'].value_counts(dropna=False)\n",
    "percent = df_corrupcao['regiao'].value_counts(dropna=False, normalize=True)\n",
    "pd.concat([contagem, percent], axis=1, keys=['contagem', '%'], sort=False)\n",
    "\n",
    "# In[3.2]: Conversão dos dados de 'regiao' para dados numéricos, a fim de\n",
    "#se mostrar a estimação de modelo com o problema da ponderação arbitrária\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_corrupcao['regiao_numerico'] = label_encoder.fit_transform(df_corrupcao['regiao'])\n",
    "df_corrupcao['regiao_numerico'] = df_corrupcao['regiao_numerico'] + 1\n",
    "df_corrupcao.head(10)\n",
    "\n",
    "# A nova variável 'regiao_numerico' é quantitativa (ERRO!), fato que\n",
    "#caracteriza a ponderação arbitrária!\n",
    "df_corrupcao['regiao_numerico'].info()\n",
    "df_corrupcao.describe()\n",
    "\n",
    "# In[3.3]: Modelando com a variável preditora numérica, resultando na\n",
    "#estimação ERRADA dos parâmetros\n",
    "# PONDERAÇÃO ARBITRÁRIA!\n",
    "modelo_corrupcao_errado = sm.OLS.from_formula(\"cpi ~ regiao_numerico\",\n",
    "                                              df_corrupcao).fit()\n",
    "\n",
    "# Parâmetros do 'modelo_corrupcao_errado'\n",
    "modelo_corrupcao_errado.summary()\n",
    "\n",
    "# In[3.4]: Plotando os fitted values do 'modelo_corrupcao_errado' considerando,\n",
    "#PROPOSITALMENTE, a ponderação arbitrária, ou seja, assumindo que as regiões\n",
    "#representam valores numéricos (América do Sul = 1; Ásia = 2; EUA e Canadá = 3;\n",
    "#Europa = 4; Oceania = 5).\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "ax =sns.regplot(\n",
    "    data=df_corrupcao,\n",
    "    x=\"regiao_numerico\", y=\"cpi\",\n",
    "    scatter_kws={\"s\": 200, \"color\": \"darkorange\", \"alpha\": 0.5},\n",
    "    line_kws={\"color\": \"indigo\"}\n",
    ")\n",
    "\n",
    "def label_point(x, y, val, ax):\n",
    "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
    "    for i, point in a.iterrows():\n",
    "        offset = 0\n",
    "        while ax.texts:\n",
    "            overlapping = False\n",
    "            for text in ax.texts:\n",
    "                overlapping |= text.get_position()[0] == (point['x'] + 0.05) and text.get_position()[1] == (point['y'] - 0.05 + offset)\n",
    "            if overlapping:\n",
    "                offset += 0.15\n",
    "            else:\n",
    "                break\n",
    "        ax.annotate(str(point['val']) + \" \" + str(point['y']),\n",
    "                    (point['x'] + 0.05,\n",
    "                     point['y'] - 0.05 + offset),\n",
    "                    fontsize=11)\n",
    "                \n",
    "plt.title('Resultado da Ponderação Arbitrária', fontsize=20)\n",
    "plt.xlabel('Região', fontsize=17)\n",
    "plt.ylabel('Corruption Perception Index', fontsize=17)\n",
    "plt.xticks(range(1, 6, 1), fontsize=14)\n",
    "plt.yticks(range(0, 11, 1), fontsize=14)\n",
    "label_point(x = df_corrupcao['regiao_numerico'],\n",
    "            y = df_corrupcao['cpi'],\n",
    "            val = df_corrupcao['pais'],\n",
    "            ax = plt.gca())\n",
    "plt.show()\n",
    "\n",
    "# In[3.5]: Dummizando a variável 'regiao'. O código abaixo automaticamente fará:\n",
    "# a) o estabelecimento de dummies que representarão cada uma das regiões do dataset;\n",
    "# b) removerá a variável original a partir da qual houve a dummização;\n",
    "# c) estabelecerá como categoria de referência a primeira categoria, ou seja,\n",
    "#a categoria 'America_do_sul' por meio do argumento 'drop_first=True'.\n",
    "\n",
    "df_corrupcao_dummies = pd.get_dummies(df_corrupcao, columns=['regiao'],\n",
    "                                      dtype=int,\n",
    "                                      drop_first=True)\n",
    "\n",
    "df_corrupcao_dummies\n",
    "\n",
    "# A variável 'regiao' estava inicialmente definida como 'object' no dataframe\n",
    "#original 'df_corrupcao'\n",
    "df_corrupcao['regiao'].info()\n",
    "\n",
    "# Este procedimento de dummização também poderia ter sido realizado em uma\n",
    "#variável do tipo 'category' ou 'string'!\n",
    "\n",
    "# In[3.6]: Estimação do modelo de regressão múltipla com n-1 dummies\n",
    "\n",
    "modelo_corrupcao_dummies = sm.OLS.from_formula(\"cpi ~ regiao_Asia + \\\n",
    "                                              regiao_EUA_e_Canada + \\\n",
    "                                              regiao_Europa + \\\n",
    "                                              regiao_Oceania\",\n",
    "                                              df_corrupcao_dummies).fit()\n",
    "\n",
    "# Parâmetros do 'modelo_corrupcao_dummies'\n",
    "modelo_corrupcao_dummies.summary()\n",
    "\n",
    "# In[3.7]: Outro método de estimação (sugestão de uso para muitas dummies no dataset)\n",
    "\n",
    "# Definição da fórmula utilizada no modelo\n",
    "lista_colunas = list(df_corrupcao_dummies.drop(columns=['cpi','pais',\n",
    "                                                        'regiao_numerico']).columns)\n",
    "formula_dummies_modelo = ' + '.join(lista_colunas)\n",
    "formula_dummies_modelo = \"cpi ~ \" + formula_dummies_modelo\n",
    "print(\"Fórmula utilizada: \",formula_dummies_modelo)\n",
    "\n",
    "# Estimação\n",
    "modelo_corrupcao_dummies = sm.OLS.from_formula(formula_dummies_modelo,\n",
    "                                               df_corrupcao_dummies).fit()\n",
    "\n",
    "# Parâmetros do 'modelo_corrupcao_dummies'\n",
    "modelo_corrupcao_dummies.summary()\n",
    "\n",
    "# In[3.8]: Plotando o 'modelo_corrupcao_dummies' de forma interpolada\n",
    "\n",
    "# Fitted values do 'modelo_corrupcao_dummies' no dataset 'df_corrupcao_dummies'\n",
    "df_corrupcao_dummies['fitted'] = modelo_corrupcao_dummies.fittedvalues\n",
    "df_corrupcao_dummies\n",
    "\n",
    "# In[3.9]: Gráfico propriamente dito\n",
    "\n",
    "from scipy import interpolate\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "df2 = df_corrupcao_dummies[['regiao_numerico',\n",
    "                            'fitted']].groupby(['regiao_numerico']).median().reset_index()\n",
    "x = df2['regiao_numerico']\n",
    "y = df2['fitted']\n",
    "\n",
    "tck = interpolate.splrep(x, y, k=2)\n",
    "xnew = np.arange(1, 5, 0.1)\n",
    "ynew = interpolate.splev(xnew, tck, der=0)\n",
    "\n",
    "def label_point(x, y, val, ax):\n",
    "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
    "    for i, point in a.iterrows():\n",
    "        offset = 0\n",
    "        while ax.texts:\n",
    "            overlapping = False\n",
    "            for text in ax.texts:\n",
    "                overlapping |= text.get_position()[0] == (point['x'] + 0.05) and text.get_position()[1] == (point['y'] - 0.05 + offset)\n",
    "            if overlapping:\n",
    "                offset += 0.15\n",
    "            else:\n",
    "                break\n",
    "        ax.annotate(str(point['val']) + \" \" + str(point['y']),\n",
    "                    (point['x'] + 0.05,\n",
    "                     point['y'] - 0.05 + offset),\n",
    "                    fontsize=11)\n",
    "\n",
    "plt.scatter(df_corrupcao_dummies['regiao_numerico'],\n",
    "            df_corrupcao_dummies['cpi'], color='darkorange', s=200, alpha=0.5)\n",
    "plt.scatter(df_corrupcao_dummies['regiao_numerico'],\n",
    "            df_corrupcao_dummies['fitted'], color='limegreen', s=240)\n",
    "plt.plot(xnew, ynew, color='indigo', linewidth=2.5)\n",
    "plt.title('Ajuste Não Linear do Modelo com Variáveis Dummy', fontsize=20)\n",
    "plt.xlabel('Região', fontsize=17)\n",
    "plt.ylabel('Corruption Perception Index', fontsize=17)\n",
    "plt.xticks(range(1, 6, 1), fontsize=14)\n",
    "plt.yticks(range(0, 11, 1), fontsize=14)\n",
    "label_point(x=df_corrupcao_dummies['regiao_numerico'],\n",
    "            y=df_corrupcao_dummies['cpi'],\n",
    "            val=df_corrupcao_dummies['pais'],\n",
    "            ax=plt.gca())\n",
    "plt.show()\n",
    "\n",
    "# In[3.10]: Gráfico gerado em HTML e aberto no browser, com interação\n",
    "#(figura 'EXEMPLO3.html' salva na pasta do curso)\n",
    "\n",
    "df2 = df_corrupcao_dummies[['regiao_numerico',\n",
    "                            'fitted']].groupby(['regiao_numerico']).median().reset_index()\n",
    "x = df2['regiao_numerico']\n",
    "y = df2['fitted']\n",
    "\n",
    "tck = interpolate.splrep(x, y, k=2)\n",
    "xnew = np.arange(1, 5, 0.1)\n",
    "ynew = interpolate.splev(xnew, tck, der=0)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_corrupcao_dummies['regiao_numerico'],\n",
    "    y=df_corrupcao_dummies['cpi'],\n",
    "    mode='markers',\n",
    "    name='CPI',\n",
    "    marker=dict(color='darkorange', size=14, opacity=0.5)\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=df_corrupcao_dummies['regiao_numerico'],\n",
    "    y=df_corrupcao_dummies['fitted'],\n",
    "    mode='markers',\n",
    "    name='Fitted',\n",
    "    marker=dict(color='limegreen', size=17)\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=xnew,\n",
    "    y=ynew,\n",
    "    mode='lines',\n",
    "    name='Interpolated',\n",
    "    line=dict(color='indigo', width=3.5)\n",
    "))\n",
    "\n",
    "fig.update_layout(title={\n",
    "        'text': 'Ajuste Não Linear do Modelo com Variáveis Dummy',\n",
    "        'font': {'size': 20, 'color': 'black', 'family': 'Arial'},\n",
    "        'x': 0.5,\n",
    "        'y': 0.95,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'\n",
    "    },\n",
    "    xaxis=dict(title='Região'),\n",
    "    yaxis=dict(title='Corruption Perception Index'),\n",
    "    xaxis_tickvals=list(range(1, 6)),\n",
    "    yaxis_tickvals=list(range(0, 11)),\n",
    "    xaxis_tickfont=dict(size=14),\n",
    "    yaxis_tickfont=dict(size=14),\n",
    "    template='plotly_white')\n",
    "\n",
    "for i in range(len(df_corrupcao_dummies)):\n",
    "    fig.add_annotation(\n",
    "        x=df_corrupcao_dummies['regiao_numerico'][i],\n",
    "        y=df_corrupcao_dummies['cpi'][i],\n",
    "        text=str(df_corrupcao_dummies['pais'][i]) + ' ' + str(df_corrupcao_dummies['cpi'][i]),\n",
    "        showarrow=False,\n",
    "        font=dict(size=11, color='black'),\n",
    "        xshift=50,\n",
    "        yshift=0,\n",
    "        textangle=0\n",
    "    )\n",
    "\n",
    "fig.update_annotations(dict(xref=\"x\", yref=\"y\"))\n",
    "fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\n",
    "fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\n",
    "\n",
    "fig.write_html('EXEMPLO3.html')\n",
    "\n",
    "# Abre o arquivo HTML no browser\n",
    "import webbrowser\n",
    "webbrowser.open('EXEMPLO3.html')\n",
    "\n",
    "\n",
    "# In[EXEMPLO 4]:\n",
    "#############################################################################\n",
    "#            REGRESSÃO NÃO LINEAR E TRANSFORMAÇÃO DE BOX-COX                #\n",
    "#               EXEMPLO 4 - CARREGAMENTO DA BASE DE DADOS                   #\n",
    "#############################################################################\n",
    "\n",
    "df_bebes = pd.read_csv('bebes.csv', delimiter=',')\n",
    "df_bebes\n",
    "\n",
    "# Características das variáveis do dataset\n",
    "df_bebes.info()\n",
    "\n",
    "# Estatísticas univariadas\n",
    "df_bebes.describe()\n",
    "\n",
    "# In[4.1]: Gráfico de dispersão\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(x=\"idade\", y=\"comprimento\", data=df_bebes, color='grey',\n",
    "                s=300, label='Valores Reais', alpha=0.7)\n",
    "plt.title('Dispersão dos dados', fontsize=20)\n",
    "plt.xlabel('Idade em semanas', fontsize=17)\n",
    "plt.ylabel('Comprimento em cm', fontsize=17)\n",
    "plt.legend(loc='lower right', fontsize=17)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# In[4.2]: Gráfico de dispersão com emojis 01\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.scatter(x=\"idade\", y=\"comprimento\", data=df_bebes, color='grey',\n",
    "            s=400, label='Valores Reais', alpha=0.7, marker='$\\U0001F607$',\n",
    "            linewidth=0.2)\n",
    "plt.title('Dispersão dos dados', fontsize=20)\n",
    "plt.xlabel('Idade em semanas', fontsize=17)\n",
    "plt.ylabel('Comprimento em cm', fontsize=17)\n",
    "plt.legend(loc='lower right', fontsize=17)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# In[4.3]: Gráfico de dispersão com emojis 02\n",
    "\n",
    "emojis_coracao = ['❤️'] * len(df_bebes)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.scatterplot(x=\"idade\", y=\"comprimento\", data=df_bebes, color='none',\n",
    "                s=0, label=None)\n",
    "for i, emoji in enumerate(emojis_coracao):\n",
    "    plt.text(df_bebes['idade'][i], df_bebes['comprimento'][i], emoji,\n",
    "             fontsize=40, ha='center', alpha=0.6, color='darkorchid')\n",
    "plt.title('Dispersão dos dados', fontsize=20)\n",
    "plt.xlabel('Idade em semanas', fontsize=17)\n",
    "plt.ylabel('Comprimento em cm', fontsize=17)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# In[4.4]: Estimação de um modelo OLS linear\n",
    "modelo_linear = sm.OLS.from_formula('comprimento ~ idade', df_bebes).fit()\n",
    "\n",
    "# Parâmetros do 'modelo_linear'\n",
    "modelo_linear.summary()\n",
    "\n",
    "# In[4.5]: Gráfico de dispersão com ajustes (fits) linear e não linear\n",
    "# com argumento 'lowess=True' (locally weighted scatterplot smoothing)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(x=\"idade\", y=\"comprimento\", data=df_bebes, color='grey',\n",
    "                s=300, label='Valores Reais', alpha=0.7)\n",
    "sns.regplot(x=\"idade\", y=\"comprimento\", data=df_bebes, lowess=True,\n",
    "            color='darkviolet', ci=False, scatter=False, label='Ajuste Não Linear',\n",
    "            line_kws={'linewidth': 2.5})\n",
    "sns.regplot(x=\"idade\", y=\"comprimento\", data=df_bebes,\n",
    "            color='darkorange', ci=False, scatter=False, label='OLS Linear',\n",
    "            line_kws={'linewidth': 2.5})\n",
    "plt.title('Dispersão dos dados e ajustes linear e não linear', fontsize=20)\n",
    "plt.xlabel('Idade em semanas', fontsize=17)\n",
    "plt.ylabel('Comprimento em cm', fontsize=17)\n",
    "plt.legend(loc='lower right', fontsize=17)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# In[4.6]: Teste de verificação da aderência dos resíduos à normalidade\n",
    "\n",
    "# Teste de Shapiro-Wilk (n < 30)\n",
    "# from scipy.stats import shapiro\n",
    "# shapiro(modelo_linear.resid)\n",
    "\n",
    "# Teste de Shapiro-Francia (n >= 30)\n",
    "# Carregamento da função 'shapiro_francia' do pacote 'statstests.tests'\n",
    "# Autores do pacote: Luiz Paulo Fávero e Helder Prado Santos\n",
    "# https://stats-tests.github.io/statstests/\n",
    "\n",
    "from statstests.tests import shapiro_francia\n",
    "\n",
    "# Teste de Shapiro-Francia: interpretação\n",
    "teste_sf = shapiro_francia(modelo_linear.resid) #criação do objeto 'teste_sf'\n",
    "teste_sf = teste_sf.items() #retorna o grupo de pares de valores-chave no dicionário\n",
    "method, statistics_W, statistics_z, p = teste_sf #definição dos elementos da lista (tupla)\n",
    "print('Statistics W=%.5f, p-value=%.6f' % (statistics_W[1], p[1]))\n",
    "alpha = 0.05 #nível de significância\n",
    "if p[1] > alpha:\n",
    "\tprint('Não se rejeita H0 - Distribuição aderente à normalidade')\n",
    "else:\n",
    "\tprint('Rejeita-se H0 - Distribuição não aderente à normalidade')\n",
    "\n",
    "# In[4.7]: Histograma dos resíduos do modelo OLS linear\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "hist1 = sns.histplot(data=modelo_linear.resid, kde=True, bins=25,\n",
    "                     color = 'darkorange', alpha=0.4, edgecolor='silver',\n",
    "                     line_kws={'linewidth': 3})\n",
    "hist1.get_lines()[0].set_color('orangered')\n",
    "plt.xlabel('Resíduos', fontsize=20)\n",
    "plt.ylabel('Frequência', fontsize=20)\n",
    "plt.xticks(fontsize=17)\n",
    "plt.yticks(fontsize=17)\n",
    "plt.show()\n",
    "\n",
    "# In[4.8]: Transformação de Box-Cox\n",
    "\n",
    "# Para o cálculo do lambda de Box-Cox\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# 'yast' é uma variável que traz os valores transformados (Y*)\n",
    "# 'lmbda' é o lambda de Box-Cox\n",
    "yast, lmbda = boxcox(df_bebes['comprimento'])\n",
    "\n",
    "# Inserção da variável transformada ('bc_comprimento') no dataset para a\n",
    "#estimação de um novo modelo\n",
    "df_bebes['bc_comprimento'] = yast\n",
    "\n",
    "df_bebes\n",
    "\n",
    "# Verificação do cálculo, apenas para fins didáticos\n",
    "df_bebes['bc_comprimento2'] = ((df_bebes['comprimento']**lmbda)-1)/lmbda\n",
    "\n",
    "df_bebes\n",
    "\n",
    "del df_bebes['bc_comprimento2']\n",
    "\n",
    "# In[4.9]: Estimando um novo modelo OLS com variável dependente\n",
    "#transformada por Box-Cox\n",
    "\n",
    "modelo_bc = sm.OLS.from_formula('bc_comprimento ~ idade', df_bebes).fit()\n",
    "\n",
    "# Parâmetros do 'modelo_bc'\n",
    "modelo_bc.summary()\n",
    "\n",
    "# In[4.10]: Comparando os parâmetros do 'modelo_linear' com os do 'modelo_bc'\n",
    "\n",
    "# CUIDADO!!! OS PARÂMETROS NÃO SÃO DIRETAMENTE COMPARÁVEIS!\n",
    "\n",
    "summary_col([modelo_linear, modelo_bc])\n",
    "\n",
    "# Outro modo mais completo também pela função 'summary_col'\n",
    "summary_col([modelo_linear, modelo_bc],\n",
    "            model_names=[\"MODELO LINEAR\",\"MODELO BOX-COX\"],\n",
    "            stars=True,\n",
    "            info_dict = {\n",
    "                'N':lambda x: \"{0:d}\".format(int(x.nobs))\n",
    "        })\n",
    "\n",
    "# Repare que há um salto na qualidade do ajuste para o modelo não linear (R²)\n",
    "\n",
    "pd.DataFrame({'R² OLS':[round(modelo_linear.rsquared,4)],\n",
    "              'R² Box-Cox':[round(modelo_bc.rsquared,4)]})\n",
    "\n",
    "# In[4.11]: Verificando a normalidade dos resíduos do 'modelo_bc'\n",
    "\n",
    "# Teste de Shapiro-Francia: interpretação\n",
    "teste_sf = shapiro_francia(modelo_bc.resid) #criação do objeto 'teste_sf'\n",
    "teste_sf = teste_sf.items() #retorna o grupo de pares de valores-chave no dicionário\n",
    "method, statistics_W, statistics_z, p = teste_sf #definição dos elementos da lista (tupla)\n",
    "print('Statistics W=%.5f, p-value=%.6f' % (statistics_W[1], p[1]))\n",
    "alpha = 0.05 #nível de significância\n",
    "if p[1] > alpha:\n",
    "\tprint('Não se rejeita H0 - Distribuição aderente à normalidade')\n",
    "else:\n",
    "\tprint('Rejeita-se H0 - Distribuição não aderente à normalidade')\n",
    "\n",
    "# In[4.12]: Histograma dos resíduos do modelo_bc\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "hist2 = sns.histplot(data=modelo_bc.resid, kde=True, bins=25,\n",
    "                     color='darkviolet', alpha=0.4, edgecolor='snow',\n",
    "                     line_kws={'linewidth': 3})\n",
    "hist2.get_lines()[0].set_color('indigo')\n",
    "plt.xlabel('Resíduos', fontsize=20)\n",
    "plt.ylabel('Frequência', fontsize=20)\n",
    "plt.xticks(fontsize=17)\n",
    "plt.yticks(fontsize=17)\n",
    "plt.show()\n",
    "\n",
    "# In[4.13]: Fazendo predições com os modelos OLS linear e Box-Cox\n",
    "# Qual é o comprimento esperado de um bebê com 52 semanas de vida?\n",
    "\n",
    "# Modelo OLS Linear:\n",
    "modelo_linear.predict(pd.DataFrame({'idade':[52]}))\n",
    "\n",
    "# Modelo Não Linear (Box-Cox):\n",
    "modelo_bc.predict(pd.DataFrame({'idade':[52]}))\n",
    "\n",
    "# Não podemos nos esquecer de fazer o cálculo inverso para a obtenção do fitted\n",
    "#value de Y (variável 'comprimento')\n",
    "(54251.109775 * lmbda + 1) ** (1 / lmbda)\n",
    "\n",
    "# In[4.14]: Salvando os fitted values dos dois modelos (modelo_linear e modelo_bc)\n",
    "#no dataset 'bebes'\n",
    "\n",
    "df_bebes['yhat_linear'] = modelo_linear.fittedvalues\n",
    "df_bebes['yhat_modelo_bc'] = (modelo_bc.fittedvalues * lmbda + 1) ** (1 / lmbda)\n",
    "df_bebes\n",
    "\n",
    "# In[4.15]: Gráfico de dispersão com ajustes dos modelos OLS linear e Box-Cox\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(x=\"idade\", y=\"comprimento\", data=df_bebes, color='grey',\n",
    "                s=350, label='Valores Reais', alpha=0.7)\n",
    "sns.regplot(x=\"idade\", y=\"yhat_modelo_bc\", data=df_bebes, order=lmbda,\n",
    "            color='darkviolet', ci=False, scatter=False, label='Box-Cox',\n",
    "            line_kws={'linewidth': 2.5})\n",
    "sns.scatterplot(x=\"idade\", y=\"yhat_modelo_bc\", data=df_bebes, color='darkviolet',\n",
    "                s=200, label='Fitted Values Box-Cox', alpha=0.5)\n",
    "sns.regplot(x=\"idade\", y=\"yhat_linear\", data=df_bebes,\n",
    "            color='darkorange', ci=False, scatter=False, label='OLS Linear',\n",
    "            line_kws={'linewidth': 2.5})\n",
    "sns.scatterplot(x=\"idade\", y=\"yhat_linear\", data=df_bebes, color='darkorange',\n",
    "                s=200, label='Fitted Values OLS Linear', alpha=0.5)\n",
    "plt.title('Dispersão dos dados e ajustes dos modelos OLS linear e Box-Cox',\n",
    "          fontsize=20)\n",
    "plt.xlabel('Idade em semanas', fontsize=17)\n",
    "plt.ylabel('Comprimento em cm', fontsize=17)\n",
    "plt.legend(loc='lower right', fontsize=17)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# In[4.16]: Gráfico de dispersão com ajustes dos modelos OLS linear e Box-Cox,\n",
    "#com interação (figura 'EXEMPLO4.html' salva na pasta do curso)\n",
    "\n",
    "# Ajuste polinomial com grau igual a lambda (lmbda = 2.659051008426254)\n",
    "coefficients = np.polyfit(df_bebes[\"idade\"], df_bebes[\"yhat_modelo_bc\"], lmbda)\n",
    "x_range = np.linspace(df_bebes[\"idade\"].min(), df_bebes[\"idade\"].max(), 100)\n",
    "y_quadratic = np.polyval(coefficients, x_range)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_bebes[\"idade\"], y=df_bebes[\"comprimento\"],\n",
    "                         mode='markers',\n",
    "                         marker=dict(color='grey', opacity=0.7, size=20),\n",
    "                         name='Valores Reais'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x_range, y=y_quadratic,\n",
    "                         mode='lines',\n",
    "                         line=dict(color='darkviolet', width=2),\n",
    "                         name='Box-Cox'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_bebes[\"idade\"], y=df_bebes[\"yhat_modelo_bc\"],\n",
    "                         mode='markers',\n",
    "                         marker=dict(color='darkviolet', opacity=0.5, size=15),\n",
    "                         name='Fitted Values Box-Cox',\n",
    "                         hovertemplate='Fitted Values Box-Cox: %{y:.2f}<extra></extra>'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_bebes[\"idade\"], y=df_bebes[\"yhat_linear\"],\n",
    "                         mode='lines',\n",
    "                         marker=dict(color='darkorange'),\n",
    "                         name='OLS Linear',\n",
    "                         hovertemplate='Fitted Values OLS Linear: %{y:.2f}<extra></extra>'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df_bebes[\"idade\"], y=df_bebes[\"yhat_linear\"],\n",
    "                         mode='markers',\n",
    "                         marker=dict(color='darkorange', opacity=0.5, size=15),\n",
    "                         name='Fitted Values OLS Linear',\n",
    "                         hovertemplate='Fitted Values OLS Linear: %{y:.2f}<extra></extra>'))\n",
    "\n",
    "fig.update_layout(title={\n",
    "        'text': 'Dispersão dos dados e ajustes dos modelos OLS linear e Box-Cox',\n",
    "        'font': {'size': 20, 'color': 'black', 'family': 'Arial'},\n",
    "        'x': 0.5,\n",
    "        'y': 0.95,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'\n",
    "    },\n",
    "    xaxis_title='Idade em semanas',\n",
    "    yaxis_title='Comprimento em cm',\n",
    "    legend=dict(x=1.02, y=1),\n",
    "    template='plotly_white')\n",
    "\n",
    "fig.update_annotations(dict(xref=\"x\", yref=\"y\"))\n",
    "fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\n",
    "fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')\n",
    "\n",
    "fig.write_html(\"EXEMPLO4.html\")\n",
    "\n",
    "# Abre o arquivo HTML no browser\n",
    "import webbrowser\n",
    "webbrowser.open('EXEMPLO4.html')\n",
    "\n",
    "\n",
    "# In[EXEMPLO 5]:\n",
    "#############################################################################\n",
    "#                        REGRESSÃO NÃO LINEAR MÚLTIPLA                      #\n",
    "#                  EXEMPLO 5 - CARREGAMENTO DA BASE DE DADOS                #\n",
    "#############################################################################\n",
    "\n",
    "df_empresas = pd.read_csv('empresas.csv', delimiter=',')\n",
    "df_empresas\n",
    "\n",
    "# Características das variáveis do dataset\n",
    "df_empresas.info()\n",
    "\n",
    "# Estatísticas univariadas\n",
    "df_empresas.describe()\n",
    "\n",
    "# In[5.1]: Matriz de correlações\n",
    "\n",
    "correlation_matrix = df_empresas.iloc[:,1:6].corr()\n",
    "correlation_matrix\n",
    "\n",
    "# Mapa de calor com as correlações entre todas as variáveis quantitativas\n",
    "plt.figure(figsize=(15, 10))\n",
    "heatmap = sns.heatmap(correlation_matrix, annot=True, fmt=\".4f\",\n",
    "                      cmap=plt.cm.viridis_r,\n",
    "                      annot_kws={'size': 25}, vmin=-1, vmax=1)\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontsize=15)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontsize=15)\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=17)\n",
    "plt.show()\n",
    "\n",
    "# In[5.2]: Matriz de correlações\n",
    "# Maneira mais elaborada pela função 'rcorr' do pacote 'pingouin'\n",
    "\n",
    "import pingouin as pg\n",
    "\n",
    "correlation_matrix2 = pg.rcorr(df_empresas, method='pearson',\n",
    "                              upper='pval', decimals=4,\n",
    "                              pval_stars={0.01: '***',\n",
    "                                          0.05: '**',\n",
    "                                          0.10: '*'})\n",
    "correlation_matrix2\n",
    "\n",
    "# In[5.3]: Diagrama interessante (grafo) que mostra a inter-relação entre as\n",
    "#variáveis e a magnitude das correlações entre elas\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Criação de um grafo direcionado\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Adição das variáveis como nós do grafo\n",
    "for variable in correlation_matrix.columns:\n",
    "    G.add_node(variable)\n",
    "\n",
    "# Adição das arestas com espessuras proporcionais às correlações\n",
    "for i, variable1 in enumerate(correlation_matrix.columns):\n",
    "    for j, variable2 in enumerate(correlation_matrix.columns):\n",
    "        if i != j:\n",
    "            correlation = correlation_matrix.iloc[i, j]\n",
    "            if abs(correlation) > 0:\n",
    "                G.add_edge(variable1, variable2, weight=correlation)\n",
    "\n",
    "# Obtenção da lista de correlações das arestas\n",
    "correlations = [d[\"weight\"] for _, _, d in G.edges(data=True)]\n",
    "\n",
    "# Definição da dimensão dos nós\n",
    "node_size = 2700\n",
    "\n",
    "# Definição da cor dos nós\n",
    "node_color = 'black'\n",
    "\n",
    "# Definição da escala de cores das retas (correspondência com as correlações)\n",
    "cmap = plt.colormaps.get_cmap('coolwarm_r')\n",
    "\n",
    "# Criação de uma lista de espessuras das arestas proporcional às correlações\n",
    "edge_widths = [abs(d[\"weight\"]) * 10 for _, _, d in G.edges(data=True)]\n",
    "\n",
    "# Criação do layout do grafo com maior distância entre os nós\n",
    "pos = nx.spring_layout(G, k=0.75)  # k para controlar a distância entre os nós\n",
    "\n",
    "# Ajuste das posições dos nós das variáveis\n",
    "pos[\"retorno\"] = (pos[\"retorno\"][0] + 1.8, pos[\"retorno\"][1] + 1.8)\n",
    "pos[\"disclosure\"] = (pos[\"disclosure\"][0], pos[\"disclosure\"][1] + 1.8)\n",
    "pos[\"endividamento\"] = (pos[\"endividamento\"][0], pos[\"endividamento\"][1] + 1.8)\n",
    "pos[\"ativos\"] = (pos[\"ativos\"][0], pos[\"ativos\"][1])\n",
    "pos[\"liquidez\"] = (pos[\"liquidez\"][0], pos[\"liquidez\"][1] + 1.8)\n",
    "\n",
    "# Desenho dos nós e das arestas com base nas correlações e espessuras\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_size, node_color=node_color)\n",
    "nx.draw_networkx_edges(G, pos, width=edge_widths, edge_color=correlations,\n",
    "                       edge_cmap=cmap, alpha=0.7)\n",
    "\n",
    "# Adição dos rótulos dos nós\n",
    "labels = {node: node for node in G.nodes}\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=7.5, font_color='white')\n",
    "\n",
    "# Ajuste dos limites dos eixos\n",
    "ax = plt.gca()\n",
    "ax.margins(0.1)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Criação da legenda com a escala de cores definida\n",
    "smp = cm.ScalarMappable(cmap=cmap)\n",
    "smp.set_array([min(correlations), max(correlations)])\n",
    "cbar = plt.colorbar(smp, ax=ax, label='Correlação')\n",
    "\n",
    "# Definição dos ticks da colorbar\n",
    "cbar.set_ticks(np.arange(round(min(correlations),0) - 0.1,\n",
    "                         max(correlations) + 0.1, 0.1))\n",
    "\n",
    "# Exibição do gráfico\n",
    "plt.show()\n",
    "\n",
    "# In[5.4]: Distribuições das variáveis, scatters, valores das correlações e\n",
    "#suas respectivas significâncias\n",
    "\n",
    "def corrfunc(x, y, **kws):\n",
    "    (r, p) = pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.3f}\".format(r),\n",
    "                xy=(.30, .9), xycoords=ax.transAxes, fontsize=16)\n",
    "    ax.annotate(\"p = {:.3f}\".format(p),\n",
    "                xy=(.30, .8), xycoords=ax.transAxes, fontsize=16)\n",
    "\n",
    "# Configuração do gráfico\n",
    "sns.set(style=\"whitegrid\", palette=\"viridis\")\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "graph = sns.pairplot(df_empresas, diag_kind=\"kde\",\n",
    "                     plot_kws={\"color\": \"darkorchid\"},\n",
    "                     height=2.5, aspect=1.7)\n",
    "graph.map(corrfunc)\n",
    "for ax in graph.axes.flat:\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=17)\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize=17)\n",
    "plt.show()\n",
    "\n",
    "# In[5.5]: Estimando o Modelo de Regressão Múltipla\n",
    "modelo_empresas = sm.OLS.from_formula('retorno ~ disclosure +\\\n",
    "                                      endividamento + ativos +\\\n",
    "                                          liquidez', df_empresas).fit()\n",
    "\n",
    "# Parâmetros do 'modelo_empresas'\n",
    "modelo_empresas.summary()\n",
    "\n",
    "# Note que o parâmetro da variável 'endividamento' não é estatisticamente\n",
    "#significante ao nível de significância de 5% (nível de confiança de 95%).\n",
    "\n",
    "# In[5.6]: Procedimento Stepwise\n",
    "\n",
    "# Carregamento da função 'stepwise' do pacote 'statstests.process'\n",
    "# Autores do pacote: Luiz Paulo Fávero e Helder Prado Santos\n",
    "# https://stats-tests.github.io/statstests/\n",
    "\n",
    "from statstests.process import stepwise\n",
    "\n",
    "# Estimação do modelo por meio do procedimento Stepwise\n",
    "modelo_step_empresas = stepwise(modelo_empresas, pvalue_limit=0.05)\n",
    "\n",
    "# In[5.7]: Teste de verificação da aderência dos resíduos à normalidade\n",
    "\n",
    "# Teste de Shapiro-Wilk (n < 30)\n",
    "#from scipy.stats import shapiro\n",
    "#shapiro(modelo_step_empresas.resid)\n",
    "\n",
    "# Teste de Shapiro-Francia (n >= 30)\n",
    "# Carregamento da função 'shapiro_francia' do pacote 'statstests.tests'\n",
    "# Autores do pacote: Luiz Paulo Fávero e Helder Prado Santos\n",
    "# https://stats-tests.github.io/statstests/\n",
    "\n",
    "from statstests.tests import shapiro_francia\n",
    "\n",
    "# Teste de Shapiro-Francia: interpretação\n",
    "teste_sf = shapiro_francia(modelo_step_empresas.resid) #criação do objeto 'teste_sf'\n",
    "teste_sf = teste_sf.items() #retorna o grupo de pares de valores-chave no dicionário\n",
    "method, statistics_W, statistics_z, p = teste_sf #definição dos elementos da lista (tupla)\n",
    "print('Statistics W=%.5f, p-value=%.6f' % (statistics_W[1], p[1]))\n",
    "alpha = 0.05 #nível de significância\n",
    "if p[1] > alpha:\n",
    "\tprint('Não se rejeita H0 - Distribuição aderente à normalidade')\n",
    "else:\n",
    "\tprint('Rejeita-se H0 - Distribuição não aderente à normalidade')\n",
    "\n",
    "# In[5.8]: Plotando os resíduos do 'modelo_step_empresas' e acrescentando\n",
    "#uma curva normal teórica para comparação entre as distribuições\n",
    "# Kernel density estimation (KDE) - forma não-paramétrica para estimação da\n",
    "#função densidade de probabilidade de determinada variável\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Calcula os valores de ajuste da distribuição normal\n",
    "(mu, sigma) = norm.fit(modelo_step_empresas.resid)\n",
    "\n",
    "# Gráfico propriamente dito\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.histplot(modelo_step_empresas.resid, bins=20, kde=True, stat=\"density\",\n",
    "             color='darkorange', alpha=0.4)\n",
    "plt.xlim(-20, 20)\n",
    "x = np.linspace(-20, 20, 100)\n",
    "p = norm.pdf(x, mu, sigma)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "plt.xlabel('Resíduos do Modelo Linear', fontsize=20)\n",
    "plt.ylabel('Frequência', fontsize=20)\n",
    "plt.xticks(fontsize=17)\n",
    "plt.yticks(fontsize=17)\n",
    "plt.show()\n",
    "\n",
    "# In[5.9]: Transformação de Box-Cox\n",
    "\n",
    "# Para o cálculo do lambda de Box-Cox\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# 'yast' é uma variável que traz os valores transformados (Y*)\n",
    "# 'lmbda' é o lambda de Box-Cox\n",
    "yast, lmbda = boxcox(df_empresas['retorno'])\n",
    "\n",
    "print(\"Lambda: \",lmbda)\n",
    "\n",
    "# In[5.10]: Inserindo o lambda de Box-Cox no dataset para a estimação de um\n",
    "#novo modelo\n",
    "\n",
    "df_empresas['bc_retorno'] = yast\n",
    "df_empresas\n",
    "\n",
    "# Verificação do cálculo, apenas para fins didáticos\n",
    "df_empresas['bc_retorno2'] = ((df_empresas['retorno'])**(lmbda) - 1) / (lmbda)\n",
    "df_empresas\n",
    "\n",
    "del df_empresas['bc_retorno2']\n",
    "\n",
    "# In[5.11]: Estimando um novo modelo múltiplo com variável dependente\n",
    "#transformada por Box-Cox\n",
    "\n",
    "modelo_bc = sm.OLS.from_formula('bc_retorno ~ disclosure +\\\n",
    "                                endividamento + ativos +\\\n",
    "                                    liquidez', df_empresas).fit()\n",
    "\n",
    "# Parâmetros do 'modelo_bc'\n",
    "modelo_bc.summary()\n",
    "\n",
    "# In[5.12]: Aplicando o procedimento Stepwise no 'modelo_bc\"\n",
    "\n",
    "modelo_step_empresas_bc = stepwise(modelo_bc, pvalue_limit=0.05)\n",
    "\n",
    "# Note que a variável 'disclosure' retorna ao modelo na forma funcional\n",
    "#não linear!\n",
    "\n",
    "# In[5.13]: Verificando a normalidade dos resíduos do 'modelo_step_empresas_bc'\n",
    "\n",
    "# Teste de Shapiro-Francia: interpretação\n",
    "teste_sf = shapiro_francia(modelo_step_empresas_bc.resid) #criação do objeto 'teste_sf'\n",
    "teste_sf = teste_sf.items() #retorna o grupo de pares de valores-chave no dicionário\n",
    "method, statistics_W, statistics_z, p = teste_sf #definição dos elementos da lista (tupla)\n",
    "print('Statistics W=%.5f, p-value=%.6f' % (statistics_W[1], p[1]))\n",
    "alpha = 0.05 #nível de significância\n",
    "if p[1] > alpha:\n",
    "\tprint('Não se rejeita H0 - Distribuição aderente à normalidade')\n",
    "else:\n",
    "\tprint('Rejeita-se H0 - Distribuição não aderente à normalidade')\n",
    "\n",
    "# In[5.14]: Plotando os novos resíduos do 'modelo_step_empresas_bc' e\n",
    "#acrescentando uma curva normal teórica para comparação entre as distribuições\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Calcula os valores de ajuste da distribuição normal\n",
    "(mu, sigma) = norm.fit(modelo_step_empresas_bc.resid)\n",
    "\n",
    "# Gráfico propriamente dito\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.histplot(modelo_step_empresas_bc.resid, bins=20, kde=True, stat=\"density\",\n",
    "             color='indigo', alpha=0.4)\n",
    "plt.xlim(-0.5, 0.5)\n",
    "x = np.linspace(-0.5, 0.5, 100)\n",
    "p = norm.pdf(x, mu, sigma)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "plt.xlabel('Resíduos do Modelo Box-Cox', fontsize=20)\n",
    "plt.ylabel('Frequência', fontsize=20)\n",
    "plt.xticks(fontsize=17)\n",
    "plt.yticks(fontsize=17)\n",
    "plt.show()\n",
    "\n",
    "# In[5.15]: Resumo dos dois modelos obtidos pelo procedimento Stepwise\n",
    "#(linear e com Box-Cox)\n",
    "\n",
    "summary_col([modelo_step_empresas, modelo_step_empresas_bc],\n",
    "            model_names=[\"STEPWISE\",\"STEPWISE BOX-COX\"],\n",
    "            stars=True,\n",
    "            info_dict = {\n",
    "                'N':lambda x: \"{0:d}\".format(int(x.nobs))\n",
    "        })\n",
    "\n",
    "# CUIDADO!!! OS PARÂMETROS NÃO SÃO DIRETAMENTE COMPARÁVEIS!\n",
    "\n",
    "# In[5.16]: Fazendo predições com o 'modelo_step_empresas_bc'\n",
    "# Qual é o valor do retorno, em média, para 'disclosure' igual a 50,\n",
    "#'liquidez' igual a 14 e 'ativos' igual a 4000, ceteris paribus?\n",
    "\n",
    "modelo_step_empresas_bc.predict(pd.DataFrame({'const':[1],\n",
    "                                              'disclosure':[50],\n",
    "                                              'ativos':[4000],\n",
    "                                              'liquidez':[14]}))\n",
    "\n",
    "\n",
    "# In[5.17]: Não podemos nos esquecer de fazer o cálculo para a obtenção do\n",
    "#fitted value de Y (variável 'retorno')\n",
    "\n",
    "(3.702016 * lmbda + 1) ** (1 / lmbda)\n",
    "\n",
    "\n",
    "# In[5.18]: Salvando os fitted values de 'modelo_step_empresas' e\n",
    "#'modelo_step_empresas_bc'\n",
    "\n",
    "df_empresas['yhat_step_empresas'] = modelo_step_empresas.fittedvalues\n",
    "df_empresas['yhat_step_empresas_bc'] = (modelo_step_empresas_bc.fittedvalues\n",
    "                                        * lmbda + 1) ** (1 / lmbda)\n",
    "\n",
    "# Visualizando os dois fitted values dos modelos 'modelo_step_empresas' e\n",
    "#'modelo_step_empresas_bc' no dataset\n",
    "df_empresas[['empresa','retorno','yhat_step_empresas','yhat_step_empresas_bc']]\n",
    "\n",
    "# In[5.19]: Ajustes dos modelos: valores previstos (fitted values) X valores reais\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def objective(x, a, b, c, d, e, f):\n",
    "    return (a * x) + (b * x**2) + (c * x**3) + (d * x**4) + (e * x**5) + f\n",
    "\n",
    "xdata = df_empresas['retorno']\n",
    "ydata_linear = df_empresas['yhat_step_empresas']\n",
    "ydata_bc = df_empresas['yhat_step_empresas_bc']\n",
    "\n",
    "plt.figure(figsize=(17,10))\n",
    "\n",
    "popt, _ = curve_fit(objective, xdata, ydata_linear)\n",
    "a, b, c, d, e, f = popt\n",
    "x_line = np.arange(min(xdata), max(xdata), 1)\n",
    "y_line = objective(x_line, a, b, c, d, e, f)\n",
    "plt.plot(x_line, y_line, '--', color='darkorange', linewidth=3)\n",
    "\n",
    "popt, _ = curve_fit(objective, xdata, ydata_bc)\n",
    "a, b, c, d, e, f = popt\n",
    "x_line = np.arange(min(xdata), max(xdata), 1)\n",
    "y_line = objective(x_line, a, b, c, d, e, f)\n",
    "plt.plot(x_line, y_line, '--', color='indigo', linewidth=3)\n",
    "\n",
    "plt.plot(xdata,xdata, color='gray', linestyle='-')\n",
    "plt.scatter(xdata,ydata_linear, alpha=0.5, s=150, color='darkorange')\n",
    "plt.scatter(xdata,ydata_bc, alpha=0.5, s=150, color='indigo')\n",
    "plt.title('Dispersão e Fitted Values dos Modelos Linear e Box-Cox',\n",
    "          fontsize=20)\n",
    "plt.xlabel('Valores Reais de Retorno', fontsize=17)\n",
    "plt.ylabel('Fitted Values', fontsize=17)\n",
    "plt.legend(['Stepwise','Stepwise com Box-Cox','45º graus'], fontsize=18)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[EXEMPLO 6]:\n",
    "#############################################################################\n",
    "#         DIAGNÓSTICO DE MULTICOLINEARIDADE EM MODELOS DE REGRESSÃO         #\n",
    "#                EXEMPLO 6 - CARREGAMENTO DA BASE DE DADOS                  #\n",
    "#############################################################################\n",
    "\n",
    "df_salarios = pd.read_csv('salarios.csv', delimiter=',')\n",
    "df_salarios\n",
    "\n",
    "# Características das variáveis do dataset\n",
    "df_salarios.info()\n",
    "\n",
    "# Estatísticas univariadas\n",
    "df_salarios.describe()\n",
    "\n",
    "# In[6.1]: Matriz de correlações\n",
    "\n",
    "correlation_matrix = df_salarios.iloc[:,1:6].corr()\n",
    "correlation_matrix\n",
    "\n",
    "# Mapa de calor com as correlações entre todas as variáveis quantitativas\n",
    "plt.figure(figsize=(15, 10))\n",
    "heatmap = sns.heatmap(correlation_matrix, annot=True, fmt=\".3f\",\n",
    "                      cmap=plt.cm.viridis_r,\n",
    "                      annot_kws={'size': 20}, vmin=-1, vmax=1)\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontsize=14)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontsize=14)\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=17)\n",
    "plt.show()\n",
    "\n",
    "# In[6.2]: CORRELAÇÃO BAIXA (variáveis 'rh1' e 'econometria1'):\n",
    "\n",
    "# Correlação entre 'rh1' e 'econometria1', com p-value\n",
    "corr1, p_value1 = pearsonr(df_salarios['rh1'], df_salarios['econometria1'])\n",
    "\"{:.4f}\".format(corr1), \"{:.4f}\".format(p_value1)\n",
    "\n",
    "# Matriz de correlação (maneira simples) pela função 'corr'\n",
    "corr1 = df_salarios[['rh1','econometria1']].corr()\n",
    "corr1\n",
    "\n",
    "# Maneira mais elaborada pela função 'rcorr' do pacote 'pingouin'\n",
    "import pingouin as pg\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "corr1b = pg.rcorr(df_salarios[['rh1','econometria1']], method='pearson',\n",
    "                  upper='pval', decimals=6,\n",
    "                  pval_stars={0.01: '***',\n",
    "                              0.05: '**',\n",
    "                              0.10: '*'})\n",
    "corr1b\n",
    "\n",
    "# Mapa de calor com a correlação entre 'rh1' e 'econometria1'\n",
    "plt.figure(figsize=(15, 10))\n",
    "heatmap = sns.heatmap(corr1, annot=True, fmt=\".4f\",\n",
    "                      cmap=plt.cm.viridis_r,\n",
    "                      annot_kws={'size': 30}, vmin=-1, vmax=1)\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontsize=17)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontsize=17)\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=17)\n",
    "plt.show()\n",
    "\n",
    "# In[6.3]: Grafo com a inter-relação entre as variáveis do dataframe 'df1'\n",
    "\n",
    "df1 = df_salarios[['salario','rh1','econometria1']]\n",
    "cormat1 = df1.corr()\n",
    "cormat1\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Criação de um grafo direcionado\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Adição das variáveis como nós do grafo\n",
    "for variable in cormat1.columns:\n",
    "    G.add_node(variable)\n",
    "\n",
    "# Adição das arestas com espessuras proporcionais às correlações\n",
    "for i, variable1 in enumerate(cormat1.columns):\n",
    "    for j, variable2 in enumerate(cormat1.columns):\n",
    "        if i != j:\n",
    "            correlation = cormat1.iloc[i, j]\n",
    "            if abs(correlation) > 0:\n",
    "                G.add_edge(variable1, variable2, weight=correlation)\n",
    "\n",
    "# Obtenção da lista de correlações das arestas\n",
    "correlations = [d[\"weight\"] for _, _, d in G.edges(data=True)]\n",
    "\n",
    "# Definição da dimensão dos nós\n",
    "node_size = 2700\n",
    "\n",
    "# Definição da cor dos nós\n",
    "node_color = 'black'\n",
    "\n",
    "# Definição da escala de cores das retas (correspondência com as correlações)\n",
    "cmap = plt.colormaps.get_cmap('viridis_r')\n",
    "\n",
    "# Criação de uma lista de espessuras das arestas proporcional às correlações\n",
    "edge_widths = [abs(d[\"weight\"]) * 10 for _, _, d in G.edges(data=True)]\n",
    "\n",
    "# Criação do layout do grafo com maior distância entre os nós\n",
    "pos = nx.spring_layout(G, k=0.75)  # k para controlar a distância entre os nós\n",
    "\n",
    "# Desenho dos nós e das arestas com base nas correlações e espessuras\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_size, node_color=node_color)\n",
    "nx.draw_networkx_edges(G, pos, width=edge_widths, edge_color=correlations,\n",
    "                       edge_cmap=cmap, alpha=0.9)\n",
    "\n",
    "# Adição dos rótulos dos nós\n",
    "labels = {node: node for node in G.nodes}\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=7.5, font_color='white')\n",
    "\n",
    "# Ajuste dos limites dos eixos\n",
    "ax = plt.gca()\n",
    "ax.margins(0.1)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Criação da legenda com a escala de cores definida\n",
    "smp = cm.ScalarMappable(cmap=cmap)\n",
    "smp.set_array([min(correlations), max(correlations)])\n",
    "cbar = plt.colorbar(smp, ax=ax, label='Correlação')\n",
    "\n",
    "# Definição dos ticks da colorbar\n",
    "cbar.set_ticks(np.arange(round(min(correlations),1),\n",
    "                         max(correlations), 0.1))\n",
    "\n",
    "# Exibição do gráfico\n",
    "plt.show()\n",
    "\n",
    "# In[6.4]: Modelo 1\n",
    "\n",
    "modelo1 = sm.OLS.from_formula('salario ~ rh1 + econometria1', df_salarios).fit()\n",
    "\n",
    "modelo1.summary()\n",
    "\n",
    "# In[6.5]: Diagnóstico de multicolinearidade (Variance Inflation Factor\n",
    "#e Tolerance)\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Calculando os valores de VIF\n",
    "X1 = sm.add_constant(df_salarios[['rh1', 'econometria1']])\n",
    "VIF = pd.DataFrame()\n",
    "VIF[\"Variável\"] = X1.columns[1:]\n",
    "VIF[\"VIF\"] = [variance_inflation_factor(X1.values, i+1)\n",
    "              for i in range(X1.shape[1]-1)]\n",
    "\n",
    "# Calculando as Tolerâncias\n",
    "VIF[\"Tolerância\"] = 1 / VIF[\"VIF\"]\n",
    "VIF\n",
    "\n",
    "# In[6.6]: CORRELAÇÃO MUITO ALTA (variáveis 'rh2' e 'econometria2'):\n",
    "\n",
    "# Correlação entre 'rh2' e 'econometria2', com p-value\n",
    "corr2, p_value2 = pearsonr(df_salarios['rh2'], df_salarios['econometria2'])\n",
    "\"{:.4f}\".format(corr2), \"{:.4f}\".format(p_value2)\n",
    "\n",
    "# Matriz de correlação (maneira simples) pela função 'corr'\n",
    "corr2 = df_salarios[['rh2','econometria2']].corr()\n",
    "corr2\n",
    "\n",
    "# Maneira mais elaborada pela função 'rcorr' do pacote 'pingouin'\n",
    "import pingouin as pg\n",
    "\n",
    "corr2b = pg.rcorr(df_salarios[['rh2','econometria2']], method='pearson',\n",
    "                  upper='pval', decimals=6,\n",
    "                  pval_stars={0.01: '***',\n",
    "                              0.05: '**',\n",
    "                              0.10: '*'})\n",
    "corr2b\n",
    "\n",
    "# Mapa de calor com a correlação entre 'rh2' e 'econometria2'\n",
    "plt.figure(figsize=(15, 10))\n",
    "heatmap = sns.heatmap(corr2, annot=True, fmt=\".4f\",\n",
    "                      cmap=plt.cm.viridis_r,\n",
    "                      annot_kws={'size': 30}, vmin=-1, vmax=1)\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontsize=17)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontsize=17)\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=17)\n",
    "plt.show()\n",
    "\n",
    "# In[6.7]: Grafo com a inter-relação entre as variáveis do dataframe 'df2'\n",
    "\n",
    "df2 = df_salarios[['salario','rh2','econometria2']]\n",
    "cormat2 = df2.corr()\n",
    "cormat2\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Criação de um grafo direcionado\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Adição das variáveis como nós do grafo\n",
    "for variable in cormat2.columns:\n",
    "    G.add_node(variable)\n",
    "\n",
    "# Adição das arestas com espessuras proporcionais às correlações\n",
    "for i, variable1 in enumerate(cormat2.columns):\n",
    "    for j, variable2 in enumerate(cormat2.columns):\n",
    "        if i != j:\n",
    "            correlation = cormat2.iloc[i, j]\n",
    "            if abs(correlation) > 0:\n",
    "                G.add_edge(variable1, variable2, weight=correlation)\n",
    "\n",
    "# Obtenção da lista de correlações das arestas\n",
    "correlations = [d[\"weight\"] for _, _, d in G.edges(data=True)]\n",
    "\n",
    "# Definição da dimensão dos nós\n",
    "node_size = 2700\n",
    "\n",
    "# Definição da cor dos nós\n",
    "node_color = 'black'\n",
    "\n",
    "# Definição da escala de cores das retas (correspondência com as correlações)\n",
    "cmap = plt.colormaps.get_cmap('viridis_r')\n",
    "\n",
    "# Criação de uma lista de espessuras das arestas proporcional às correlações\n",
    "edge_widths = [abs(d[\"weight\"]) * 10 for _, _, d in G.edges(data=True)]\n",
    "\n",
    "# Criação do layout do grafo com maior distância entre os nós\n",
    "pos = nx.spring_layout(G, k=0.75)  # k para controlar a distância entre os nós\n",
    "\n",
    "# Desenho dos nós e das arestas com base nas correlações e espessuras\n",
    "nx.draw_networkx_nodes(G, pos, node_size=node_size, node_color=node_color)\n",
    "nx.draw_networkx_edges(G, pos, width=edge_widths, edge_color=correlations,\n",
    "                       edge_cmap=cmap, alpha=0.9)\n",
    "\n",
    "# Adição dos rótulos dos nós\n",
    "labels = {node: node for node in G.nodes}\n",
    "nx.draw_networkx_labels(G, pos, labels, font_size=7.5, font_color='white')\n",
    "\n",
    "# Ajuste dos limites dos eixos\n",
    "ax = plt.gca()\n",
    "ax.margins(0.1)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Criação da legenda com a escala de cores definida\n",
    "smp = cm.ScalarMappable(cmap=cmap)\n",
    "smp.set_array([min(correlations), max(correlations)])\n",
    "cbar = plt.colorbar(smp, ax=ax, label='Correlação')\n",
    "\n",
    "# Definição dos ticks da colorbar\n",
    "cbar.set_ticks(np.arange(round(min(correlations) - 0.01,2),\n",
    "                         max(correlations) + 0.01, 0.01))\n",
    "\n",
    "# Exibição do gráfico\n",
    "plt.show()\n",
    "\n",
    "# In[6.8]: Modelo 2\n",
    "\n",
    "modelo2 = sm.OLS.from_formula('salario ~ rh2 + econometria2', df_salarios).fit()\n",
    "\n",
    "modelo2.summary()\n",
    "\n",
    "# In[6.9]: Diagnóstico de multicolinearidade (Variance Inflation Factor\n",
    "#e Tolerance)\n",
    "\n",
    "# Calculando os valores de VIF\n",
    "X2 = sm.add_constant(df_salarios[['rh2', 'econometria2']])\n",
    "VIF = pd.DataFrame()\n",
    "VIF[\"Variável\"] = X2.columns[1:]\n",
    "VIF[\"VIF\"] = [variance_inflation_factor(X2.values, i+1)\n",
    "              for i in range(X2.shape[1]-1)]\n",
    "\n",
    "# Calculando as Tolerâncias\n",
    "VIF[\"Tolerância\"] = 1 / VIF[\"VIF\"]\n",
    "VIF\n",
    "\n",
    "\n",
    "# In[EXEMPLO 7]:\n",
    "#############################################################################\n",
    "#        DIAGNÓSTICO DE HETEROCEDASTICIDADE EM MODELOS DE REGRESSÃO         #\n",
    "#               EXEMPLO 7 - CARREGAMENTO DA BASE DE DADOS                   #\n",
    "#############################################################################\n",
    "    \n",
    "df_saeb_rend = pd.read_csv('saeb_rend.csv', delimiter=',')\n",
    "df_saeb_rend\n",
    "\n",
    "# Características das variáveis do dataset\n",
    "df_saeb_rend.info()\n",
    "\n",
    "# Estatísticas univariadas\n",
    "df_saeb_rend.describe()\n",
    "\n",
    "# In[7.1]: Tabela de frequências absolutas das variáveis 'uf' e rede'\n",
    "\n",
    "df_saeb_rend['uf'].value_counts().sort_index()\n",
    "df_saeb_rend['rede'].value_counts().sort_index()\n",
    "\n",
    "# In[7.2]: Plotando a variável 'saeb' em função de 'rendimento', com fit linear\n",
    "# Gráfico pela função 'regplot' do 'seaborn'\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(x='rendimento', y='saeb', data=df_saeb_rend, marker='o',\n",
    "            color='royalblue', ci=False,\n",
    "            scatter_kws={'color':'lightsalmon', 'alpha':0.5, 's':150},\n",
    "            line_kws={'linewidth': 4})\n",
    "plt.title('Gráfico de Dispersão com Ajuste Linear', fontsize=22)\n",
    "plt.xlabel('rendimento', fontsize=20)\n",
    "plt.ylabel('saeb', fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "# In[7.3]: Plotando a variável 'saeb' em função de 'rendimento', com destaque\n",
    "#para a 'rede' escolar e linear fits -> Gráfico pela função 'regplot' do\n",
    "#pacote 'seaborn'\n",
    "\n",
    "# Definição de dataframes com subgrupos por 'rede'\n",
    "df1 = df_saeb_rend[df_saeb_rend['rede'] == 'Municipal']\n",
    "df2 = df_saeb_rend[df_saeb_rend['rede'] == 'Estadual']\n",
    "df3 = df_saeb_rend[df_saeb_rend['rede'] == 'Federal']\n",
    "\n",
    "# Gráfico propriamente dito\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(x='rendimento', y='saeb', data=df1, marker='o', ci=False,\n",
    "            scatter_kws={'color':'darkorange', 'alpha':0.3, 's':150},\n",
    "            line_kws={'color':'darkorange', 'linewidth': 4}, label='Municipal')\n",
    "sns.regplot(x='rendimento', y='saeb', data=df2, marker='o', ci=False,\n",
    "            scatter_kws={'color':'darkviolet', 'alpha':0.3, 's':150},\n",
    "            line_kws={'color':'darkviolet', 'linewidth': 4}, label='Estadual')\n",
    "sns.regplot(x='rendimento', y='saeb', data=df3, marker='o', ci=False,\n",
    "            scatter_kws={'color':'darkgreen', 'alpha':0.8, 's':150},\n",
    "            line_kws={'color':'darkgreen', 'linewidth': 4}, label='Federal')\n",
    "plt.title('Gráfico de Dispersão com Ajuste Linear por Rede', fontsize=22)\n",
    "plt.xlabel('rendimento', fontsize=20)\n",
    "plt.ylabel('saeb', fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.legend(fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "# In[7.4]: Estimação do modelo de regressão e diagnóstico de heterocedasticidade\n",
    "\n",
    "# Estimando o modelo\n",
    "modelo_saeb = sm.OLS.from_formula('saeb ~ rendimento', df_saeb_rend).fit()\n",
    "\n",
    "# Parâmetros do 'modelo_saeb'\n",
    "modelo_saeb.summary()\n",
    "\n",
    "# In[7.5]: Adicionando fitted values e resíduos do 'modelo_saeb' no\n",
    "# dataset 'df_saeb_rend'\n",
    "\n",
    "df_saeb_rend['fitted'] = modelo_saeb.fittedvalues\n",
    "df_saeb_rend['residuos'] = modelo_saeb.resid\n",
    "df_saeb_rend\n",
    "\n",
    "# In[7.6]: Gráfico que relaciona resíduos e fitted values do 'modelo_saeb'\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(x='fitted', y='residuos', data=df_saeb_rend,\n",
    "            marker='o', fit_reg=False,\n",
    "            scatter_kws={\"color\":'red', 'alpha':0.2, 's':150})\n",
    "plt.title('Gráfico de Dispersão entre Resíduos e Fitted Values', fontsize=22)\n",
    "plt.xlabel('Fitted Values do Modelo', fontsize=20)\n",
    "plt.ylabel('Resíduos do Modelo', fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "# In[7.7]: Histograma dos resíduos do 'modelo_saeb' com curva normal teórica\n",
    "#para comparação das distribuições\n",
    "# Kernel density estimation (KDE) - forma não-paramétrica para estimação da\n",
    "#função densidade de probabilidade de determinada variável\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Calcula os valores de ajuste da distribuição normal\n",
    "(mu, sigma) = norm.fit(modelo_saeb.resid)\n",
    "\n",
    "# Gráfico propriamente dito\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.histplot(modelo_saeb.resid, bins=20, kde=True, stat=\"density\",\n",
    "             color='red', alpha=0.4)\n",
    "plt.xlim(-4, 4)\n",
    "x = np.linspace(-4, 4, 100)\n",
    "p = norm.pdf(x, mu, sigma)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "plt.xlabel('Resíduos do Modelo Linear', fontsize=20)\n",
    "plt.ylabel('Frequência', fontsize=20)\n",
    "plt.xticks(fontsize=17)\n",
    "plt.yticks(fontsize=17)\n",
    "plt.show()\n",
    "\n",
    "# In[7.8]: Função para o teste de Breusch-Pagan para a elaboração de diagnóstico\n",
    "#de heterocedasticidade\n",
    "\n",
    "# Criação da função 'breusch_pagan_test'\n",
    "\n",
    "def breusch_pagan_test(modelo):\n",
    "\n",
    "    df = pd.DataFrame({'yhat':modelo.fittedvalues,\n",
    "                       'resid':modelo.resid})\n",
    "   \n",
    "    df['up'] = (np.square(df.resid))/np.sum(((np.square(df.resid))/df.shape[0]))\n",
    "   \n",
    "    modelo_aux = sm.OLS.from_formula('up ~ yhat', df).fit()\n",
    "   \n",
    "    anova_table = sm.stats.anova_lm(modelo_aux, typ=2)\n",
    "   \n",
    "    anova_table['sum_sq'] = anova_table['sum_sq']/2\n",
    "    \n",
    "    chisq = anova_table['sum_sq'].iloc[0]\n",
    "   \n",
    "    p_value = stats.chi2.pdf(chisq, 1)*2\n",
    "    \n",
    "    print(f\"chisq: {chisq}\")\n",
    "    \n",
    "    print(f\"p-value: {p_value}\")\n",
    "    \n",
    "    return chisq, p_value\n",
    "\n",
    "# In[7.9]: Teste de Breusch-Pagan propriamente dito\n",
    "\n",
    "breusch_pagan_test(modelo_saeb)\n",
    "# Presença de heterocedasticidade -> omissão de variável(is) explicativa(s)\n",
    "#relevante(s)\n",
    "\n",
    "# H0 do teste: ausência de heterocedasticidade.\n",
    "# H1 do teste: heterocedasticidade, ou seja, correlação entre resíduos e\n",
    "#uma ou mais variáveis explicativas, o que indica omissão de variável relevante!\n",
    "\n",
    "# Interpretação\n",
    "teste_bp = breusch_pagan_test(modelo_saeb) #criação do objeto 'teste_bp'\n",
    "chisq, p = teste_bp #definição dos elementos contidos no objeto 'teste_bp'\n",
    "alpha = 0.05 #nível de significância\n",
    "if p > alpha:\n",
    "    print('Não se rejeita H0 - Ausência de Heterocedasticidade')\n",
    "else:\n",
    "\tprint('Rejeita-se H0 - Existência de Heterocedasticidade')\n",
    "\n",
    "# In[7.10]: Procedimento n-1 dummies para as unidades federativas\n",
    "    \n",
    "# Dummização da variável 'uf'\n",
    "\n",
    "df_saeb_rend_dummies = pd.get_dummies(df_saeb_rend, columns=['uf'],\n",
    "                                      dtype=int,\n",
    "                                      drop_first=True)\n",
    "\n",
    "df_saeb_rend_dummies\n",
    "\n",
    "# In[7.11]: Estimação do modelo de regressão múltipla com n-1 dummies\n",
    "\n",
    "# Definição da fórmula utilizada no modelo\n",
    "lista_colunas = list(df_saeb_rend_dummies.drop(columns=['municipio',\n",
    "                                                        'codigo',\n",
    "                                                        'escola',\n",
    "                                                        'rede',\n",
    "                                                        'saeb',\n",
    "                                                        'fitted',\n",
    "                                                        'residuos']).columns)\n",
    "formula_dummies_modelo = ' + '.join(lista_colunas)\n",
    "formula_dummies_modelo = \"saeb ~ \" + formula_dummies_modelo\n",
    "\n",
    "# Estimação\n",
    "modelo_saeb_dummies_uf = sm.OLS.from_formula(formula_dummies_modelo,\n",
    "                                               df_saeb_rend_dummies).fit()\n",
    "\n",
    "# Parâmetros do modelo 'modelo_saeb_dummies_uf'\n",
    "modelo_saeb_dummies_uf.summary()\n",
    "\n",
    "# In[7.12]: Estimação do modelo por meio do procedimento Stepwise\n",
    "\n",
    "# Carregamento da função 'stepwise' do pacote 'statstests.process'\n",
    "# Autores do pacote: Luiz Paulo Fávero e Helder Prado Santos\n",
    "# https://stats-tests.github.io/statstests/\n",
    "\n",
    "from statstests.process import stepwise\n",
    "\n",
    "modelo_saeb_dummies_uf_step = stepwise(modelo_saeb_dummies_uf, pvalue_limit=0.05)\n",
    "\n",
    "# In[7.13]: Teste de Breusch-Pagan para diagnóstico de heterocedasticidade\n",
    "#no 'modelo_saeb_dummies_uf_step'\n",
    "\n",
    "breusch_pagan_test(modelo_saeb_dummies_uf_step)\n",
    "\n",
    "# Interpretação\n",
    "teste_bp = breusch_pagan_test(modelo_saeb_dummies_uf_step) #criação do objeto 'teste_bp'\n",
    "chisq, p = teste_bp #definição dos elementos contidos no objeto 'teste_bp'\n",
    "alpha = 0.05 #nível de significância\n",
    "if p > alpha:\n",
    "    print('Não se rejeita H0 - Ausência de Heterocedasticidade')\n",
    "else:\n",
    "\tprint('Rejeita-se H0 - Existência de Heterocedasticidade')\n",
    "\n",
    "# In[7.14]: Adicionando fitted values e resíduos do 'modelo_saeb_dummies_uf_step'\n",
    "#no dataset 'df_saeb_rend'\n",
    "\n",
    "df_saeb_rend['fitted_step'] = modelo_saeb_dummies_uf_step.fittedvalues\n",
    "df_saeb_rend['residuos_step'] = modelo_saeb_dummies_uf_step.resid\n",
    "df_saeb_rend\n",
    "\n",
    "# In[7.15]: Gráfico que relaciona resíduos e fitted values do\n",
    "#'modelo_saeb_dummies_uf_step'\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(x='fitted_step', y='residuos_step', data=df_saeb_rend,\n",
    "            marker='o', fit_reg=False,\n",
    "            scatter_kws={\"color\":'dodgerblue', 'alpha':0.2, 's':150})\n",
    "plt.title('Gráfico de Dispersão entre Resíduos e Fitted Values', fontsize=22)\n",
    "plt.xlabel('Fitted Values do Modelo Stepwise com Dummies', fontsize=20)\n",
    "plt.ylabel('Resíduos do Modelo Stepwise com Dummies', fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "# In[7.16]: Histograma dos resíduos do 'modelo_saeb_dummies_uf_step' com curva\n",
    "#normal teórica para comparação das distribuições\n",
    "# Kernel density estimation (KDE) - forma não-paramétrica para estimação da\n",
    "#função densidade de probabilidade de determinada variável\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Calcula os valores de ajuste da distribuição normal\n",
    "(mu, sigma) = norm.fit(modelo_saeb_dummies_uf_step.resid)\n",
    "\n",
    "# Gráfico propriamente dito\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.histplot(modelo_saeb_dummies_uf_step.resid, bins=20, kde=True,\n",
    "             stat=\"density\", color='dodgerblue', alpha=0.4)\n",
    "plt.xlim(-4, 4)\n",
    "x = np.linspace(-4, 4, 100)\n",
    "p = norm.pdf(x, mu, sigma)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "plt.xlabel('Resíduos do Modelo Stepwise com Dummies', fontsize=20)\n",
    "plt.ylabel('Frequência', fontsize=20)\n",
    "plt.xticks(fontsize=17)\n",
    "plt.yticks(fontsize=17)\n",
    "plt.show()\n",
    "\n",
    "# In[7.17]: Plotando a variável 'saeb' em função de 'rendimento', com destaque\n",
    "#para as unidades federativas e fits lineares - Gráfico pela função 'lmplot' do\n",
    "#pacote 'seaborn', com estratificação de 'uf' pelo argumento 'hue'\n",
    "\n",
    "uf_order = df_saeb_rend['uf'].value_counts().index.sort_values()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.lmplot(x='rendimento', y='saeb', data=df_saeb_rend,\n",
    "           hue='uf', ci=None, palette='viridis', legend=False,\n",
    "           scatter_kws={'alpha': 0.5},\n",
    "           hue_order=uf_order)\n",
    "plt.title('Gráfico de Dispersão com Ajuste Linear por UF', fontsize=13)\n",
    "plt.xlabel('rendimento', fontsize=12)\n",
    "plt.ylabel('saeb', fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(fontsize=10, ncol=3, bbox_to_anchor=(1, 0.75))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[EXEMPLO 8]:\n",
    "#############################################################################\n",
    "#                 REGRESSÃO NÃO LINEAR MÚLTIPLA COM DUMMIES                 #\n",
    "#                 EXEMPLO 8 - CARREGAMENTO DA BASE DE DADOS                 #\n",
    "#############################################################################\n",
    "\n",
    "df_planosaude = pd.read_csv('planosaude.csv', delimiter=',')\n",
    "df_planosaude\n",
    "\n",
    "# Características das variáveis do dataset\n",
    "df_planosaude.info()\n",
    "\n",
    "# Estatísticas univariadas\n",
    "df_planosaude.describe()\n",
    "\n",
    "# In[8.1]: Tabela de frequências absolutas da variável 'plano'\n",
    "\n",
    "df_planosaude['plano'].value_counts().sort_index()\n",
    "\n",
    "# In[8.2]: Distribuições das variáveis, scatters, valores das correlações e\n",
    "#suas respectivas significâncias\n",
    "\n",
    "def corrfunc(x, y, **kws):\n",
    "    (r, p) = pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.3f}\".format(r),\n",
    "                xy=(.30, .9), xycoords=ax.transAxes, fontsize=16)\n",
    "    ax.annotate(\"p = {:.3f}\".format(p),\n",
    "                xy=(.30, .8), xycoords=ax.transAxes, fontsize=16)\n",
    "\n",
    "# Configuração do gráfico\n",
    "sns.set(style=\"whitegrid\", palette=\"viridis\")\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "graph = sns.pairplot(df_planosaude.loc[:,'despmed':'renda'], diag_kind=\"kde\",\n",
    "                     plot_kws={\"color\": \"darkorange\"},\n",
    "                     height=2.5, aspect=1.7)\n",
    "graph.map(corrfunc)\n",
    "for ax in graph.axes.flat:\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=17)\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize=17)\n",
    "plt.show()\n",
    "\n",
    "# In[8.3]: Dummizando a variável 'plano' (n-1 dummies)\n",
    "\n",
    "df_planosaude_dummies = pd.get_dummies(df_planosaude, columns=['plano'],\n",
    "                                       dtype=int,\n",
    "                                       drop_first=True)\n",
    "\n",
    "df_planosaude_dummies\n",
    "\n",
    "# In[8.4]: Estimação do modelo de regressão múltipla com n-1 dummies\n",
    "\n",
    "# Definição da fórmula utilizada no modelo\n",
    "lista_colunas = list(df_planosaude_dummies.drop(columns=['id',\n",
    "                                                         'despmed']).columns)\n",
    "formula_dummies_modelo = ' + '.join(lista_colunas)\n",
    "formula_dummies_modelo = \"despmed ~ \" + formula_dummies_modelo\n",
    "\n",
    "# Estimação\n",
    "modelo_planosaude = sm.OLS.from_formula(formula_dummies_modelo,\n",
    "                                        df_planosaude_dummies).fit()\n",
    "\n",
    "# Parâmetros do modelo\n",
    "modelo_planosaude.summary()\n",
    "\n",
    "# In[8.5]: Procedimento Stepwise\n",
    "\n",
    "# Carregamento da função 'stepwise' do pacote 'statstests.process'\n",
    "# Autores do pacote: Luiz Paulo Fávero e Helder Prado Santos\n",
    "# https://stats-tests.github.io/statstests/\n",
    "\n",
    "from statstests.process import stepwise\n",
    "\n",
    "# Estimação do modelo por meio do procedimento Stepwise\n",
    "modelo_step_planosaude = stepwise(modelo_planosaude, pvalue_limit=0.05)\n",
    "\n",
    "# In[8.6]: Teste de verificação da aderência dos resíduos à normalidade\n",
    "\n",
    "# Teste de Shapiro-Francia (n >= 30)\n",
    "# Carregamento da função 'shapiro_francia' do pacote 'statstests.tests'\n",
    "# Autores do pacote: Luiz Paulo Fávero e Helder Prado Santos\n",
    "# https://stats-tests.github.io/statstests/\n",
    "\n",
    "from statstests.tests import shapiro_francia\n",
    "\n",
    "# Teste de Shapiro-Francia: interpretação\n",
    "teste_sf = shapiro_francia(modelo_step_planosaude.resid) #criação do objeto 'teste_sf'\n",
    "teste_sf = teste_sf.items() #retorna o grupo de pares de valores-chave no dicionário\n",
    "method, statistics_W, statistics_z, p = teste_sf #definição dos elementos da lista (tupla)\n",
    "print('Statistics W=%.5f, p-value=%.6f' % (statistics_W[1], p[1]))\n",
    "alpha = 0.05 #nível de significância\n",
    "if p[1] > alpha:\n",
    "\tprint('Não se rejeita H0 - Distribuição aderente à normalidade')\n",
    "else:\n",
    "\tprint('Rejeita-se H0 - Distribuição não aderente à normalidade')\n",
    "\n",
    "# In[8.7]: Histograma dos resíduos do 'modelo_step_planosaude' com curva normal\n",
    "#teórica para comparação das distribuições\n",
    "# Kernel density estimation (KDE) - forma não-paramétrica para estimação da\n",
    "#função densidade de probabilidade de determinada variável\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Calcula os valores de ajuste da distribuição normal\n",
    "(mu, sigma) = norm.fit(modelo_step_planosaude.resid)\n",
    "\n",
    "# Gráfico propriamente dito\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.histplot(modelo_step_planosaude.resid, bins=15, kde=True, stat=\"density\",\n",
    "             color='red', alpha=0.4)\n",
    "plt.xlim(-60, 70)\n",
    "x = np.linspace(-60, 70, 100)\n",
    "p = norm.pdf(x, mu, sigma)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "plt.xlabel('Resíduos do Modelo Stepwise Linear', fontsize=20)\n",
    "plt.ylabel('Frequência', fontsize=20)\n",
    "plt.xticks(fontsize=17)\n",
    "plt.yticks(fontsize=17)\n",
    "plt.show()\n",
    "\n",
    "# In[8.8]: Função para o teste de Breusch-Pagan para a elaboração de diagnóstico\n",
    "#de heterocedasticidade\n",
    "\n",
    "# Criação da função 'breusch_pagan_test'\n",
    "\n",
    "def breusch_pagan_test(modelo):\n",
    "\n",
    "    df = pd.DataFrame({'yhat':modelo.fittedvalues,\n",
    "                       'resid':modelo.resid})\n",
    "   \n",
    "    df['up'] = (np.square(df.resid))/np.sum(((np.square(df.resid))/df.shape[0]))\n",
    "   \n",
    "    modelo_aux = sm.OLS.from_formula('up ~ yhat', df).fit()\n",
    "   \n",
    "    anova_table = sm.stats.anova_lm(modelo_aux, typ=2)\n",
    "   \n",
    "    anova_table['sum_sq'] = anova_table['sum_sq']/2\n",
    "    \n",
    "    chisq = anova_table['sum_sq'].iloc[0]\n",
    "   \n",
    "    p_value = stats.chi2.pdf(chisq, 1)*2\n",
    "    \n",
    "    print(f\"chisq: {chisq}\")\n",
    "    \n",
    "    print(f\"p-value: {p_value}\")\n",
    "    \n",
    "    return chisq, p_value\n",
    "\n",
    "# In[8.9]: Teste de Breusch-Pagan propriamente dito\n",
    "\n",
    "breusch_pagan_test(modelo_step_planosaude)\n",
    "# Presença de heterocedasticidade -> omissão de variável(is) explicativa(s)\n",
    "#relevante(s)\n",
    "\n",
    "# H0 do teste: ausência de heterocedasticidade.\n",
    "# H1 do teste: heterocedasticidade, ou seja, correlação entre resíduos e\n",
    "#uma ou mais variáveis explicativas, o que indica omissão de variável relevante!\n",
    "\n",
    "# Interpretação\n",
    "teste_bp = breusch_pagan_test(modelo_step_planosaude) #criação do objeto 'teste_bp'\n",
    "chisq, p = teste_bp #definição dos elementos contidos no objeto 'teste_bp'\n",
    "alpha = 0.05 #nível de significância\n",
    "if p > alpha:\n",
    "    print('Não se rejeita H0 - Ausência de Heterocedasticidade')\n",
    "else:\n",
    "\tprint('Rejeita-se H0 - Existência de Heterocedasticidade')\n",
    "\n",
    "# In[8.10]: Adicionando fitted values e resíduos do 'modelo_step_planosaude'\n",
    "#no dataframe 'df_planosaude_dummies'\n",
    "\n",
    "df_planosaude_dummies['fitted_step'] = modelo_step_planosaude.fittedvalues\n",
    "df_planosaude_dummies['residuos_step'] = modelo_step_planosaude.resid\n",
    "df_planosaude_dummies\n",
    "\n",
    "# In[8.11]: Gráfico que relaciona resíduos e fitted values do\n",
    "#'modelo_step_planosaude'\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(x='fitted_step', y='residuos_step', data=df_planosaude_dummies,\n",
    "            marker='o', fit_reg=False,\n",
    "            scatter_kws={\"color\":'red', 'alpha':0.5, 's':200})\n",
    "plt.title('Gráfico de Dispersão entre Resíduos e Fitted Values', fontsize=22)\n",
    "plt.xlabel('Fitted Values do Modelo Stepwise', fontsize=20)\n",
    "plt.ylabel('Resíduos do Modelo Stepwise', fontsize=20)\n",
    "plt.xticks(fontsize=17)\n",
    "plt.yticks(np.arange(-50, 71, 20), fontsize=17)\n",
    "x_min = df_planosaude_dummies['fitted_step'].min()-1\n",
    "x_max = df_planosaude_dummies['fitted_step'].max()+1\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.show()\n",
    "\n",
    "# In[8.12]: Gráfico que relaciona resíduos e fitted values do\n",
    "#'modelo_step_planosaude', com boundaries\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(x='fitted_step', y='residuos_step', data=df_planosaude_dummies,\n",
    "            marker='o', fit_reg=False,\n",
    "            scatter_kws={\"color\":'red', 'alpha':0.5, 's':200})\n",
    "plt.title('Gráfico de Dispersão entre Resíduos e Fitted Values', fontsize=22)\n",
    "plt.xlabel('Fitted Values do Modelo Stepwise', fontsize=20)\n",
    "plt.ylabel('Resíduos do Modelo Stepwise', fontsize=20)\n",
    "plt.xticks(fontsize=17)\n",
    "plt.yticks(np.arange(-50, 71, 20), fontsize=17)\n",
    "x_min = df_planosaude_dummies['fitted_step'].min()-1\n",
    "x_max = df_planosaude_dummies['fitted_step'].max()+1\n",
    "plt.xlim(x_min, x_max)\n",
    "\n",
    "sns.kdeplot(data=df_planosaude_dummies, x='fitted_step', y='residuos_step',\n",
    "            levels=2, color='red', linewidths=3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# In[8.13]: Transformação de Box-Cox\n",
    "\n",
    "# Para o cálculo do lambda de Box-Cox\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "# 'yast' é uma variável que traz os valores transformados (Y*)\n",
    "# 'lmbda' é o lambda de Box-Cox\n",
    "yast, lmbda = boxcox(df_planosaude_dummies['despmed'])\n",
    "\n",
    "print(\"Lambda: \",lmbda)\n",
    "\n",
    "# In[8.14]: Inserindo o lambda de Box-Cox no dataset para a estimação de um\n",
    "#novo modelo\n",
    "\n",
    "df_planosaude_dummies['bc_despmed'] = yast\n",
    "df_planosaude_dummies\n",
    "\n",
    "# Verificação do cálculo, apenas para fins didáticos\n",
    "df_planosaude_dummies['bc_despmed2'] = ((df_planosaude_dummies['despmed'])**\\\n",
    "                                        (lmbda) - 1) / (lmbda)\n",
    "df_planosaude_dummies\n",
    "\n",
    "del df_planosaude_dummies['bc_despmed2']\n",
    "\n",
    "# In[8.15]: Estimando um novo modelo com todas as variáveis e a variável\n",
    "#dependente transformada\n",
    "modelo_bc_planosaude = sm.OLS.from_formula('bc_despmed ~ idade + dcron +\\\n",
    "                                           renda + plano_esmeralda +\\\n",
    "                                               plano_ouro',\n",
    "                                               df_planosaude_dummies).fit()\n",
    "\n",
    "# Parâmetros do modelo\n",
    "modelo_bc_planosaude.summary()\n",
    "\n",
    "# In[8.16]: Procedimento Stepwise no 'modelo_bc_planosaude'\n",
    "\n",
    "modelo_step_bc_planosaude = stepwise(modelo_bc_planosaude, pvalue_limit=0.05)\n",
    "\n",
    "# In[8.17]: Teste de verificação da aderência à normalidade dos resíduos do novo\n",
    "#'modelo_step_bc_planosaude'\n",
    "\n",
    "# Teste de Shapiro-Francia: interpretação\n",
    "teste_sf = shapiro_francia(modelo_step_bc_planosaude.resid) #criação do objeto 'teste_sf'\n",
    "teste_sf = teste_sf.items() #retorna o grupo de pares de valores-chave no dicionário\n",
    "method, statistics_W, statistics_z, p = teste_sf #definição dos elementos da lista (tupla)\n",
    "print('Statistics W=%.5f, p-value=%.6f' % (statistics_W[1], p[1]))\n",
    "alpha = 0.05 #nível de significância\n",
    "if p[1] > alpha:\n",
    "\tprint('Não se rejeita H0 - Distribuição aderente à normalidade')\n",
    "else:\n",
    "\tprint('Rejeita-se H0 - Distribuição não aderente à normalidade')\n",
    "\n",
    "# In[8.18]: Histograma dos resíduos do 'modelo_step_bc_planosaude' com curva\n",
    "#normal teórica para comparação das distribuições\n",
    "# Kernel density estimation (KDE) - forma não-paramétrica para estimação da\n",
    "#função densidade de probabilidade de determinada variável\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Calcula os valores de ajuste da distribuição normal\n",
    "(mu, sigma) = norm.fit(modelo_step_bc_planosaude.resid)\n",
    "\n",
    "# Gráfico propriamente dito\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.histplot(modelo_step_bc_planosaude.resid, bins=15, kde=True, stat=\"density\",\n",
    "             color='limegreen', alpha=0.4)\n",
    "plt.xlim(-0.15, 0.15)\n",
    "x = np.linspace(-0.15, 0.15, 100)\n",
    "p = norm.pdf(x, mu, sigma)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "plt.xlabel('Resíduos do Modelo Stepwise com Box-Cox', fontsize=20)\n",
    "plt.ylabel('Frequência', fontsize=20)\n",
    "plt.xticks(fontsize=17)\n",
    "plt.yticks(fontsize=17)\n",
    "plt.show()\n",
    "\n",
    "# In[8.19]: Teste de Breusch-Pagan para diagnóstico de heterocedasticidade\n",
    "#no 'modelo_step_bc_planosaude'\n",
    "\n",
    "breusch_pagan_test(modelo_step_bc_planosaude)\n",
    "\n",
    "# Interpretação\n",
    "teste_bp = breusch_pagan_test(modelo_step_bc_planosaude) #criação do objeto 'teste_bp'\n",
    "chisq, p = teste_bp #definição dos elementos contidos no objeto 'teste_bp'\n",
    "alpha = 0.05 #nível de significância\n",
    "if p > alpha:\n",
    "    print('Não se rejeita H0 - Ausência de Heterocedasticidade')\n",
    "else:\n",
    "\tprint('Rejeita-se H0 - Existência de Heterocedasticidade')\n",
    "\n",
    "# In[8.20]: Adicionando fitted values e resíduos do 'modelo_step_bc_planosaude'\n",
    "#no dataframe 'df_planosaude_dummies'\n",
    "\n",
    "df_planosaude_dummies['fitted_step_bc'] = modelo_step_bc_planosaude.fittedvalues\n",
    "df_planosaude_dummies['residuos_step_bc'] = modelo_step_bc_planosaude.resid\n",
    "df_planosaude_dummies\n",
    "\n",
    "# In[8.21]: Gráfico que relaciona resíduos e fitted values do\n",
    "#'modelo_step_bc_planosaude'\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(x='fitted_step_bc', y='residuos_step_bc', data=df_planosaude_dummies,\n",
    "            marker='o', fit_reg=False,\n",
    "            scatter_kws={\"color\":'limegreen', 'alpha':0.5, 's':200})\n",
    "plt.title('Gráfico de Dispersão entre Resíduos e Fitted Values', fontsize=22)\n",
    "plt.xlabel('Fitted Values do Modelo Stepwise com Box-Cox', fontsize=20)\n",
    "plt.ylabel('Resíduos do Modelo Stepwise com Box-Cox', fontsize=20)\n",
    "plt.xticks(fontsize=17)\n",
    "plt.yticks(np.arange(-.15, .16, .05), fontsize=17)\n",
    "x_min = df_planosaude_dummies['fitted_step_bc'].min()-0.01\n",
    "x_max = df_planosaude_dummies['fitted_step_bc'].max()+0.01\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.show()\n",
    "\n",
    "# In[8.22]: Gráfico que relaciona resíduos e fitted values do\n",
    "#'modelo_step_bc_planosaude', com boundaries\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.regplot(x='fitted_step_bc', y='residuos_step_bc', data=df_planosaude_dummies,\n",
    "            marker='o', fit_reg=False,\n",
    "            scatter_kws={\"color\": 'limegreen', 'alpha': 0.5, 's': 200})\n",
    "plt.title('Gráfico de Dispersão entre Resíduos e Fitted Values', fontsize=22)\n",
    "plt.xlabel('Fitted Values do Modelo Stepwise com Box-Cox', fontsize=20)\n",
    "plt.ylabel('Resíduos do Modelo Stepwise com Box-Cox', fontsize=20)\n",
    "plt.xticks(fontsize=17)\n",
    "plt.yticks(np.arange(-.15, .16, .05), fontsize=17)\n",
    "x_min = df_planosaude_dummies['fitted_step_bc'].min()-0.01\n",
    "x_max = df_planosaude_dummies['fitted_step_bc'].max()+0.01\n",
    "plt.xlim(x_min, x_max)\n",
    "\n",
    "sns.kdeplot(data=df_planosaude_dummies, x='fitted_step_bc', y='residuos_step_bc',\n",
    "            levels=2, color='green', linewidths=3)\n",
    "\n",
    "################################## FIM ######################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
