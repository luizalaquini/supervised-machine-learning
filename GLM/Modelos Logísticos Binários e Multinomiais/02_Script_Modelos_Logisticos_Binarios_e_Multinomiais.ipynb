{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UNIVERSIDADE DE SÃO PAULO**<br>\n",
    "**MBA DATA SCIENCE & ANALYTICS USP/ESALQ**<br>\n",
    "**SUPERVISED MACHINE LEARNING: ANÁLISE DE REGRESSÃO SIMPLES E MÚLTIPLA**<br>\n",
    "**Prof. Dr. Luiz Paulo Fávero**<br>\n",
    "Aluna: Luiza Batista Laquini<br>\n",
    "Turma: DSA 241<br>\n",
    "\n",
    "*coding: utf-8*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[0.1]: Instalação dos pacotes\n",
    "\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install -U seaborn\n",
    "# !pip install matplotlib\n",
    "# !pip install plotly\n",
    "# !pip install scipy\n",
    "# !pip install statsmodels\n",
    "# !pip install scikit-learn\n",
    "# !pip install statstests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[0.2]: Importação dos pacotes\n",
    "\n",
    "import pandas as pd # manipulação de dados em formato de dataframe\n",
    "import numpy as np # operações matemáticas\n",
    "import seaborn as sns # visualização gráfica\n",
    "import matplotlib.pyplot as plt # visualização gráfica\n",
    "from scipy.interpolate import UnivariateSpline # curva sigmoide suavizada\n",
    "import statsmodels.api as sm # estimação de modelos\n",
    "import statsmodels.formula.api as smf # estimação do modelo logístico binário\n",
    "from statstests.process import stepwise # procedimento Stepwise\n",
    "from scipy import stats # estatística chi2\n",
    "import plotly.graph_objects as go # gráficos 3D\n",
    "from statsmodels.iolib.summary2 import summary_col # comparação entre modelos\n",
    "from statsmodels.discrete.discrete_model import MNLogit # estimação do modelo\n",
    "                                                        #logístico multinomial\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[PARTE CONCEITUAL]:\n",
    "#############################################################################\n",
    "#                             CURVA SIGMOIDE                                #\n",
    "#############################################################################\n",
    "\n",
    "# Estabelecendo uma função para a probabilidade de ocorrência de um evento\n",
    "\n",
    "from math import exp\n",
    "\n",
    "# Estabelecendo uma função para a probabilidade de ocorrência de um evento\n",
    "def prob(z):\n",
    "    return 1 / (1 + exp(-z))\n",
    "\n",
    "# In[SIGMOIDE]: Plotando a curva sigmoide teórica de ocorrência de um evento\n",
    "#para um range do logito z entre -5 e +5\n",
    "\n",
    "logitos = []\n",
    "probs = []\n",
    "\n",
    "for i in np.arange(-5, 6):\n",
    "    logitos.append(i)\n",
    "    probs.append(prob(i))\n",
    "    \n",
    "df = pd.DataFrame({'logito': logitos, 'probs': probs})\n",
    "\n",
    "# Interpolação spline (smooth probability line)\n",
    "spline = UnivariateSpline(df['logito'], df['probs'], s=0)\n",
    "\n",
    "logitos_smooth = np.linspace(df['logito'].min(), df['logito'].max(), 500)\n",
    "probs_smooth = spline(logitos_smooth)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(logitos_smooth, probs_smooth, color='royalblue',\n",
    "         linestyle='--', label='Prob. Evento')\n",
    "plt.scatter(df['logito'], df['probs'], color='royalblue', marker='o', s=250)\n",
    "plt.axhline(y = df.probs.mean(), color = 'grey', linestyle = ':', xmax = .5)\n",
    "plt.axvline(x = 0, color = 'grey', linestyle=':', ymax = 0.5)\n",
    "plt.xlabel(\"Logito Z\", fontsize=20)\n",
    "plt.ylabel(\"Probabilidade\", fontsize=20)\n",
    "plt.xticks(np.arange(-5, 6), fontsize=14)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1), fontsize=14)\n",
    "plt.legend(fontsize=18, loc='center right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[EXEMPLO 1]:\n",
    "#############################################################################\n",
    "#                      REGRESSÃO LOGÍSTICA BINÁRIA                          #                  \n",
    "#               EXEMPLO 1 - CARREGAMENTO DA BASE DE DADOS                   #\n",
    "#############################################################################\n",
    "\n",
    "df_atrasado = pd.read_csv('atrasado.csv',delimiter=',')\n",
    "df_atrasado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Características das variáveis do dataset\n",
    "df_atrasado.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas univariadas\n",
    "df_atrasado.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1.1]: Tabela de frequências absolutas da variável 'atrasado'\n",
    "\n",
    "df_atrasado['atrasado'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1.2]: Estimação de um modelo logístico binário pela função 'smf.glm'\n",
    "#('statsmodels.formula.api')\n",
    "\n",
    "modelo_atrasos = smf.glm(formula='atrasado ~ dist + sem', data=df_atrasado,\n",
    "                         family=sm.families.Binomial()).fit()\n",
    "\n",
    "# Parâmetros do 'modelo_atrasos'\n",
    "modelo_atrasos.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1.3]: Outputs do modelo pela função 'summary_col'\n",
    "\n",
    "summary_col([modelo_atrasos],\n",
    "            model_names=[\"MODELO\"],\n",
    "            stars=True,\n",
    "            info_dict = {\n",
    "                'N':lambda x: \"{0:d}\".format(int(x.nobs)),\n",
    "                'Log-lik':lambda x: \"{:.3f}\".format(x.llf)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1.4]: Fazendo predições para o 'modelo_atrasos'.\n",
    "#Exemplo: qual a probabilidade média de se chegar atrasado quando o\n",
    "#trajeto tem 7 km e passa-se por 10 semáforos no percurso?\n",
    "\n",
    "modelo_atrasos.predict(pd.DataFrame({'dist':[7], 'sem':[10]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1.5]: Construção de uma matriz de confusão\n",
    "\n",
    "# Adicionando os valores previstos de probabilidade na base de dados\n",
    "df_atrasado['phat'] = modelo_atrasos.predict()\n",
    "\n",
    "# Visualização da base de dados com a variável 'phat'\n",
    "df_atrasado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1.6]: Gráficos com ajustes entre a variável dependente e a variável 'sem'\n",
    "    \n",
    "# Ajuste linear entre a variável dependente e a variável 'sem' (Gráfico errado:\n",
    "#apenas para fins didáticos)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(x=df_atrasado['sem'], y=df_atrasado['atrasado'],\n",
    "            ci=None, marker='o',\n",
    "            scatter_kws={'color':'orange', 's':250, 'alpha':0.7},\n",
    "            line_kws={'color':'darkorchid', 'linewidth':7})\n",
    "plt.axhline(y = 0.5, color = 'grey', linestyle = ':')\n",
    "plt.xlabel('Quantidade de Semáforos', fontsize=20)\n",
    "plt.ylabel('Atrasado', fontsize=20)\n",
    "plt.xticks(np.arange(0, df_atrasado['sem'].max() + 0.01),\n",
    "           fontsize=14)\n",
    "plt.yticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.show\n",
    "\n",
    "# In[1.7]: Ajuste logístico determinístico entre a variável dependente e a\n",
    "#variável 'sem'\n",
    "\n",
    "# Sigmoide\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(x=df_atrasado['sem'], y=df_atrasado['atrasado'],\n",
    "            ci=None, marker='o', logistic=True,\n",
    "            scatter_kws={'color':'orange', 's':250, 'alpha':0.7},\n",
    "            line_kws={'color':'darkorchid', 'linewidth':7})\n",
    "plt.axhline(y = 0.5, color = 'grey', linestyle = ':')\n",
    "plt.xlabel('Quantidade de Semáforos', fontsize=20)\n",
    "plt.ylabel('Atrasado', fontsize=20)\n",
    "plt.xticks(np.arange(0, df_atrasado['sem'].max() + 0.01),\n",
    "           fontsize=14)\n",
    "plt.yticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.show\n",
    "\n",
    "# In[1.8]: Ajuste logístico probabilístico entre a variável dependente e a\n",
    "#variável 'sem'\n",
    "\n",
    "# Sigmoide\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.regplot(x=df_atrasado['sem'], y=df_atrasado['phat'],\n",
    "            ci=None, marker='o', logistic=True,\n",
    "            scatter_kws={'color':'orange', 's':250, 'alpha':0.7},\n",
    "            line_kws={'color':'darkorchid', 'linewidth':7})\n",
    "plt.axhline(y = 0.5, color = 'grey', linestyle = ':')\n",
    "plt.xlabel('Quantidade de Semáforos', fontsize=20)\n",
    "plt.ylabel('Atrasado', fontsize=20)\n",
    "plt.xticks(np.arange(0, df_atrasado['sem'].max() + 0.01),\n",
    "           fontsize=14)\n",
    "plt.yticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.show\n",
    "\n",
    "# In[1.9]: Construção de função para a definição da matriz de confusão\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,\\\n",
    "    ConfusionMatrixDisplay, recall_score\n",
    "\n",
    "def matriz_confusao(predicts, observado, cutoff):\n",
    "    \n",
    "    values = predicts.values\n",
    "    \n",
    "    predicao_binaria = []\n",
    "        \n",
    "    for item in values:\n",
    "        if item < cutoff:\n",
    "            predicao_binaria.append(0)\n",
    "        else:\n",
    "            predicao_binaria.append(1)\n",
    "           \n",
    "    cm = confusion_matrix(predicao_binaria, observado)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Classified')\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "        \n",
    "    sensitividade = recall_score(observado, predicao_binaria, pos_label=1)\n",
    "    especificidade = recall_score(observado, predicao_binaria, pos_label=0)\n",
    "    acuracia = accuracy_score(observado, predicao_binaria)\n",
    "\n",
    "    # Visualização dos principais indicadores desta matriz de confusão\n",
    "    indicadores = pd.DataFrame({'Sensitividade':[sensitividade],\n",
    "                                'Especificidade':[especificidade],\n",
    "                                'Acurácia':[acuracia]})\n",
    "    return indicadores\n",
    "\n",
    "# In[1.10]: Matrizes de confusão propriamente ditas\n",
    "\n",
    "# Matriz de confusão para cutoff = 0.5\n",
    "matriz_confusao(observado=df_atrasado['atrasado'],\n",
    "                predicts=df_atrasado['phat'], \n",
    "                cutoff=0.5)\n",
    "\n",
    "# Matriz de confusão para cutoff = 0.3\n",
    "matriz_confusao(observado=df_atrasado['atrasado'],\n",
    "                predicts=df_atrasado['phat'], \n",
    "                cutoff=0.3)\n",
    "\n",
    "# Matriz de confusão para cutoff = 0.7\n",
    "matriz_confusao(observado=df_atrasado['atrasado'],\n",
    "                predicts=df_atrasado['phat'], \n",
    "                cutoff=0.7)\n",
    "\n",
    "# In[1.11]: Igualando critérios de especificidade e de sensitividade\n",
    "\n",
    "# Tentaremos estabelecer um critério que iguale a probabilidade de\n",
    "#acerto daqueles que chegarão atrasados (sensitividade) e a probabilidade de\n",
    "#acerto daqueles que não chegarão atrasados (especificidade).\n",
    "\n",
    "# ATENÇÃO: o que será feito a seguir possui fins didáticos, apenas. DE NENHUMA\n",
    "#FORMA, o procedimento garante a maximização da acurácia do modelo!\n",
    "\n",
    "# Criação da função 'espec_sens' para a construção de um dataset com diferentes\n",
    "#valores de cutoff, sensitividade e especificidade:\n",
    "\n",
    "def espec_sens(observado,predicts):\n",
    "    \n",
    "    # Adicionar objeto com os valores dos predicts\n",
    "    values = predicts.values\n",
    "    \n",
    "    # Range dos cutoffs a serem analisados em steps de 0.01\n",
    "    cutoffs = np.arange(0,1.01,0.01)\n",
    "    \n",
    "    # Listas que receberão os resultados de especificidade e sensitividade\n",
    "    lista_sensitividade = []\n",
    "    lista_especificidade = []\n",
    "    \n",
    "    for cutoff in cutoffs:\n",
    "        \n",
    "        predicao_binaria = []\n",
    "        \n",
    "        # Definindo resultado binário de acordo com o predict\n",
    "        for item in values:\n",
    "            if item >= cutoff:\n",
    "                predicao_binaria.append(1)\n",
    "            else:\n",
    "                predicao_binaria.append(0)\n",
    "                \n",
    "        # Cálculo da sensitividade e especificidade no cutoff\n",
    "        sensitividade = recall_score(observado, predicao_binaria, pos_label=1)\n",
    "        especificidadee = recall_score(observado, predicao_binaria, pos_label=0)\n",
    "        \n",
    "        # Adicionar valores nas listas\n",
    "        lista_sensitividade.append(sensitividade)\n",
    "        lista_especificidade.append(especificidadee)\n",
    "        \n",
    "    # Criar dataframe com os resultados nos seus respectivos cutoffs\n",
    "    resultado = pd.DataFrame({'cutoffs':cutoffs,'sensitividade':lista_sensitividade,'especificidade':lista_especificidade})\n",
    "    return resultado\n",
    "\n",
    "# In[1.12]: Até o momento, foram extraídos 3 vetores: 'sensitividade',\n",
    "#'especificidade' e 'cutoffs'. Assim, criamos um dataframe que contém\n",
    "#os vetores mencionados (dataframe 'dados_plotagem')\n",
    "\n",
    "dados_plotagem = espec_sens(observado = df_atrasado['atrasado'],\n",
    "                            predicts = df_atrasado['phat'])\n",
    "dados_plotagem\n",
    "\n",
    "# In[1.13]: Plotagem de um gráfico que mostra a variação da especificidade e da\n",
    "#sensitividade em função do cutoff\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "with plt.style.context('seaborn-v0_8-whitegrid'):\n",
    "    plt.plot(dados_plotagem.cutoffs,dados_plotagem.sensitividade, marker='o',\n",
    "         color='indigo', markersize=8)\n",
    "    plt.plot(dados_plotagem.cutoffs,dados_plotagem.especificidade, marker='o',\n",
    "         color='limegreen', markersize=8)\n",
    "plt.xlabel('Cuttoff', fontsize=20)\n",
    "plt.ylabel('Sensitividade / Especificidade', fontsize=20)\n",
    "plt.xticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.yticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.legend(['Sensitividade', 'Especificidade'], fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# In[1.14]: Construção da curva ROC\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Função 'roc_curve' do pacote 'metrics' do sklearn\n",
    "\n",
    "fpr, tpr, thresholds =roc_curve(df_atrasado['atrasado'], df_atrasado['phat'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Cálculo do coeficiente de GINI\n",
    "gini = (roc_auc - 0.5)/(0.5)\n",
    "\n",
    "# Plotando a curva ROC\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(fpr, tpr, marker='o', color='darkorchid', markersize=10, linewidth=3)\n",
    "plt.plot(fpr, fpr, color='gray', linestyle='dashed')\n",
    "plt.title('Área abaixo da curva: %g' % round(roc_auc, 4) +\n",
    "          ' | Coeficiente de GINI: %g' % round(gini, 4), fontsize=22)\n",
    "plt.xlabel('1 - Especificidade', fontsize=20)\n",
    "plt.ylabel('Sensitividade', fontsize=20)\n",
    "plt.xticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.yticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[EXEMPLO 2]:\n",
    "#############################################################################\n",
    "#           REGRESSÃO LOGÍSTICA BINÁRIA E PROCEDIMENTO STEPWISE             #        \n",
    "#                EXEMPLO 2 - CARREGAMENTO DA BASE DE DADOS                  #\n",
    "#############################################################################\n",
    "\n",
    "df_challenger = pd.read_csv('challenger.csv',delimiter=',')\n",
    "df_challenger\n",
    "\n",
    "# Características das variáveis do dataset\n",
    "df_challenger.info()\n",
    "\n",
    "# Estatísticas univariadas\n",
    "df_challenger.describe()\n",
    "\n",
    "# desgaste: quantidade de vezes em que ocorreu stress térmico\n",
    "# temperatura: temperatura de lançamento (graus ºF)\n",
    "# pressão: pressão de verificação de vazamento (psi: libra-força por\n",
    "    #polegada ao quadrado)\n",
    "# t: teste para o lançamento (id)\n",
    "\n",
    "# In[2.1]: Criação da variável dependente binária 'falha'\n",
    "\n",
    "# Não há uma variável binária para servir como uma variável dependente, certo?\n",
    "# Então vamos criá-la, considerando a ocorrência de desgastes de peças como a\n",
    "#ocorrência de um evento que chamaremos de 'falha':\n",
    "\n",
    "df_challenger.loc[df_challenger['desgaste'] != 0 , 'falha'] = 1\n",
    "df_challenger.loc[df_challenger['desgaste'] == 0, 'falha'] = 0\n",
    "\n",
    "# Transformando a variável 'falha' para o tipo 'int' (poderia também deixar\n",
    "#como 'float'), a fim de que seja possível estimar o modelo por meio da\n",
    "#função 'sm.Logit.from_formula'\n",
    "\n",
    "df_challenger.info()\n",
    "\n",
    "df_challenger['falha'] = df_challenger['falha'].astype('int64')\n",
    "\n",
    "df_challenger.info()\n",
    "\n",
    "df_challenger\n",
    "\n",
    "# In[2.2]: Gráfico 'pairplot' com scatters e KDEs por 'falha'\n",
    "\n",
    "cores_desejadas = {0: 'springgreen', 1: 'magenta'}\n",
    "\n",
    "g = sns.pairplot(df_challenger[['falha','temperatura','pressão']], hue='falha',\n",
    "                 palette=cores_desejadas)\n",
    "g.fig.set_size_inches(8, 6)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[2.3]: Estimação do modelo logístico binário pela função 'sm.Logit.from_formula'\n",
    "#('statsmodels.api')\n",
    "\n",
    "# O modelo a seguir também pode ser estimado por meio da função 'smf.glm'\n",
    "#('statsmodels.formula.api')\n",
    "\n",
    "modelo_challenger = sm.Logit.from_formula('falha ~ temperatura + pressão',\n",
    "                                          df_challenger).fit()\n",
    "\n",
    "# Parâmetros do 'modelo_challenger'\n",
    "modelo_challenger.summary()\n",
    "\n",
    "# In[2.4]: Procedimento Stepwise\n",
    "\n",
    "# Carregamento da função 'stepwise' do pacote 'statstests.process'\n",
    "# Autores do pacote: Luiz Paulo Fávero e Helder Prado Santos\n",
    "# https://stats-tests.github.io/statstests/\n",
    "\n",
    "from statstests.process import stepwise\n",
    "\n",
    "# Estimação do modelo por meio do procedimento Stepwise\n",
    "step_challenger = stepwise(modelo_challenger, pvalue_limit=0.05)\n",
    "\n",
    "# In[2.5]: Fazendo predições para o modelo 'step_challenger'\n",
    "\n",
    "# Exemplo 1: qual a probabilidade média de falha a 70ºF (~21.11ºC)?\n",
    "step_challenger.predict(pd.DataFrame({'temperatura':[70]}))\n",
    "\n",
    "# Exemplo 2: qual a probabilidade média de falha a 77ºF (25ºC)?\n",
    "step_challenger.predict(pd.DataFrame({'temperatura':[77]}))\n",
    "\n",
    "# Exemplo 3: qual a probabilidade média de falha a 34ºF (~1.11ºC)?\n",
    "# Temperatura no momento do lançamento\n",
    "step_challenger.predict(pd.DataFrame({'temperatura':[34]}))\n",
    "\n",
    "# In[2.6]: Atribuindo uma coluna no dataframe para os resultados\n",
    "\n",
    "df_challenger['phat'] = step_challenger.predict()\n",
    "\n",
    "df_challenger\n",
    "\n",
    "# In[2.7]: Construção da sigmoide\n",
    "# Probabilidade de evento em função da variável 'temperatura'    \n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(x=df_challenger['temperatura'][df_challenger['falha'] == 0],\n",
    "                y=df_challenger['falha'][df_challenger['falha'] == 0],\n",
    "                color='springgreen', alpha=0.7, s=250, label='Falha = 0')\n",
    "sns.scatterplot(x=df_challenger['temperatura'][df_challenger['falha'] == 1],\n",
    "                y=df_challenger['falha'][df_challenger['falha'] == 1],\n",
    "                color='magenta', alpha=0.7, s=250, label='Falha = 1')\n",
    "sns.regplot(x=df_challenger['temperatura'], y=df_challenger['falha'],\n",
    "            logistic=True, ci=None, scatter=False,\n",
    "            line_kws={'color': 'indigo', 'linewidth': 7})\n",
    "plt.axhline(y = 0.5, color = 'grey', linestyle = ':')\n",
    "plt.xlabel('Temperatura em ºF', fontsize=20)\n",
    "plt.ylabel('Probabilidade de Falha', fontsize=20)\n",
    "plt.xticks(np.arange(df_challenger['temperatura'].min(),\n",
    "                     df_challenger['temperatura'].max() + 0.01, 3),\n",
    "           fontsize=14)\n",
    "plt.yticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.legend(fontsize=20, loc='center right')\n",
    "plt.show()\n",
    "\n",
    "# In[2.8]: Nossa homenagem aos astronautas\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "url = \"https://img.ibxk.com.br///2016/01/29/29182307148581.jpg?w=1200&h=675&mode=crop&scale=both\"\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img.show()    \n",
    "\n",
    "\n",
    "# In[EXEMPLO 3]:\n",
    "#############################################################################\n",
    "#  REGRESSÃO LOGÍSTICA BINÁRIA COM VARIÁVEIS EXPLICATIVAS QUANTI E QUALIS   #\n",
    "#                EXEMPLO 3 - CARREGAMENTO DA BASE DE DADOS                  #\n",
    "#############################################################################\n",
    "\n",
    "df_fidelidade = pd.read_csv('dados_fidelidade.csv',delimiter=',')\n",
    "df_fidelidade\n",
    "\n",
    "# Características das variáveis do dataset\n",
    "df_fidelidade.info()\n",
    "\n",
    "# Estatísticas univariadas\n",
    "df_fidelidade.describe()\n",
    "\n",
    "# In[3.1]: Alteração dos tipos das variáveis não quantitativas no dataframe\n",
    "\n",
    "# Transformação do 'id' para o tipo 'str'\n",
    "df_fidelidade['id'] = df_fidelidade['id'].astype('str')\n",
    "\n",
    "# Transformação das variáveis explicativas qualitativas para o tipo 'object'\n",
    "df_fidelidade['atendimento'] = df_fidelidade['atendimento'].astype('object')\n",
    "df_fidelidade['sortimento'] = df_fidelidade['sortimento'].astype('object')\n",
    "df_fidelidade['acessibilidade'] = df_fidelidade['acessibilidade'].astype('object')\n",
    "df_fidelidade['preço'] = df_fidelidade['preço'].astype('object')\n",
    "\n",
    "# Características das variáveis do dataset\n",
    "df_fidelidade.info()\n",
    "\n",
    "# Estatísticas univariadas\n",
    "df_fidelidade.describe()\n",
    "\n",
    "# In[3.2]: Tabela de frequências absolutas das variáveis qualitativas referentes\n",
    "#aos atributos da loja na percepção dos consumidores\n",
    "\n",
    "df_fidelidade['fidelidade'].value_counts().sort_index()\n",
    "df_fidelidade['sexo'].value_counts().sort_index()\n",
    "df_fidelidade['atendimento'].value_counts().sort_index()\n",
    "df_fidelidade['sortimento'].value_counts().sort_index()\n",
    "df_fidelidade['acessibilidade'].value_counts().sort_index()\n",
    "df_fidelidade['preço'].value_counts().sort_index()\n",
    "\n",
    "# In[3.3]: Note que a variável Y 'fidelidade' está definida como objeto\n",
    "#(PROBLEMA!!!)\n",
    "\n",
    "# Transformando a variável Y para 0 e 1 e para o tipo 'int' (poderia também\n",
    "#ser do tipo 'float'), a fim de que seja possível estimar o modelo por meio\n",
    "#da função 'sm.Logit.from_formula'\n",
    "\n",
    "df_fidelidade.loc[df_fidelidade['fidelidade']=='sim', 'fidelidade'] = 1\n",
    "df_fidelidade.loc[df_fidelidade['fidelidade']=='nao', 'fidelidade'] = 0\n",
    "\n",
    "df_fidelidade['fidelidade'] = df_fidelidade['fidelidade'].astype('int64')\n",
    "\n",
    "df_fidelidade\n",
    "\n",
    "# In[3.4]: Dummizando as variáveis 'atendimento', 'sortimento', 'acessibilidade',\n",
    "#'preço' e 'sexo'. O código abaixo, automaticamente, fará:\n",
    "# a) a dummização das variáveis originais;\n",
    "# b) a remoção das variáveis dummizadas originais;\n",
    "# c) a definição das categorias de label 1 de cada variável original como\n",
    "#categorias de referência, por meio do argumento 'drop_first=True'.\n",
    "\n",
    "df_fidelidade_dummies = pd.get_dummies(df_fidelidade,\n",
    "                                       columns=['atendimento',\n",
    "                                                'sortimento',\n",
    "                                                'acessibilidade',\n",
    "                                                'preço',\n",
    "                                                'sexo'],\n",
    "                                       dtype=int,\n",
    "                                       drop_first=True)\n",
    "\n",
    "df_fidelidade_dummies\n",
    "\n",
    "# In[3.5]: Estimação do modelo logístico binário\n",
    "\n",
    "# Sugestão de uso neste caso, dada a existência de muitas dummies no dataframe\n",
    "# Definição da fórmula utilizada no modelo\n",
    "\n",
    "lista_colunas = list(df_fidelidade_dummies.drop(columns=['id',\n",
    "                                                         'fidelidade']).columns)\n",
    "formula_dummies_modelo = ' + '.join(lista_colunas)\n",
    "formula_dummies_modelo = \"fidelidade ~ \" + formula_dummies_modelo\n",
    "print(\"Fórmula utilizada: \",formula_dummies_modelo)\n",
    "\n",
    "# Modelo propriamente dito\n",
    "modelo_fidelidade = sm.Logit.from_formula(formula_dummies_modelo,\n",
    "                                               df_fidelidade_dummies).fit()\n",
    "\n",
    "# Parâmetros do 'modelo_fidelidade'\n",
    "modelo_fidelidade.summary()\n",
    "\n",
    "# In[3.6]: Procedimento Stepwise\n",
    "\n",
    "# Carregamento da função 'stepwise' do pacote 'statstests.process'\n",
    "# Autores do pacote: Luiz Paulo Fávero e Helder Prado Santos\n",
    "# https://stats-tests.github.io/statstests/\n",
    "\n",
    "from statstests.process import stepwise\n",
    "\n",
    "#Estimação do modelo por meio do procedimento Stepwise\n",
    "step_modelo_fidelidade = stepwise(modelo_fidelidade, pvalue_limit=0.05)\n",
    "\n",
    "# In[3.7]: Construção de função para a definição da matriz de confusão\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score,\\\n",
    "    ConfusionMatrixDisplay, recall_score\n",
    "\n",
    "def matriz_confusao(predicts, observado, cutoff):\n",
    "    \n",
    "    values = predicts.values\n",
    "    \n",
    "    predicao_binaria = []\n",
    "        \n",
    "    for item in values:\n",
    "        if item < cutoff:\n",
    "            predicao_binaria.append(0)\n",
    "        else:\n",
    "            predicao_binaria.append(1)\n",
    "           \n",
    "    cm = confusion_matrix(predicao_binaria, observado)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Classified')\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "        \n",
    "    sensitividade = recall_score(observado, predicao_binaria, pos_label=1)\n",
    "    especificidade = recall_score(observado, predicao_binaria, pos_label=0)\n",
    "    acuracia = accuracy_score(observado, predicao_binaria)\n",
    "\n",
    "    #Visualizando os principais indicadores desta matriz de confusão\n",
    "    indicadores = pd.DataFrame({'Sensitividade':[sensitividade],\n",
    "                                'Especificidade':[especificidade],\n",
    "                                'Acurácia':[acuracia]})\n",
    "    return indicadores\n",
    "\n",
    "# In[3.8]: Construção da matriz de confusão\n",
    "\n",
    "# Adicionando os valores previstos de probabilidade na base de dados\n",
    "df_fidelidade_dummies['phat'] = step_modelo_fidelidade.predict()\n",
    "\n",
    "# Matriz de confusão para cutoff = 0.5\n",
    "matriz_confusao(observado=df_fidelidade_dummies['fidelidade'],\n",
    "                predicts=df_fidelidade_dummies['phat'],\n",
    "                cutoff=0.50)\n",
    "\n",
    "# In[3.9]: Igualando critérios de especificidade e de sensitividade\n",
    "\n",
    "# Tentaremos estabelecer um critério que iguale a probabilidade de\n",
    "#acerto daqueles que chegarão atrasados (sensitividade) e a probabilidade de\n",
    "#acerto daqueles que não chegarão atrasados (especificidade).\n",
    "\n",
    "# ATENÇÃO: o que será feito a seguir possui fins didáticos, apenas. DE NENHUMA\n",
    "#FORMA o procedimento garante a maximização da acurácia do modelo!\n",
    "\n",
    "# Criação da função 'espec_sens' para a construção de um dataset com diferentes\n",
    "#valores de cutoff, sensitividade e especificidade:\n",
    "\n",
    "def espec_sens(observado,predicts):\n",
    "    \n",
    "    # adicionar objeto com os valores dos predicts\n",
    "    values = predicts.values\n",
    "    \n",
    "    # range dos cutoffs a serem analisados em steps de 0.01\n",
    "    cutoffs = np.arange(0,1.01,0.01)\n",
    "    \n",
    "    # Listas que receberão os resultados de especificidade e sensitividade\n",
    "    lista_sensitividade = []\n",
    "    lista_especificidade = []\n",
    "    \n",
    "    for cutoff in cutoffs:\n",
    "        \n",
    "        predicao_binaria = []\n",
    "        \n",
    "        # Definindo resultado binário de acordo com o predict\n",
    "        for item in values:\n",
    "            if item >= cutoff:\n",
    "                predicao_binaria.append(1)\n",
    "            else:\n",
    "                predicao_binaria.append(0)\n",
    "                \n",
    "        # Cálculo da sensitividade e especificidade no cutoff\n",
    "        sensitividade = recall_score(observado, predicao_binaria, pos_label=1)\n",
    "        especificidadee = recall_score(observado, predicao_binaria, pos_label=0)\n",
    "        \n",
    "        # Adicionar valores nas listas\n",
    "        lista_sensitividade.append(sensitividade)\n",
    "        lista_especificidade.append(especificidadee)\n",
    "        \n",
    "    # Criar dataframe com os resultados nos seus respectivos cutoffs\n",
    "    resultado = pd.DataFrame({'cutoffs':cutoffs,'sensitividade':lista_sensitividade,'especificidade':lista_especificidade})\n",
    "    return resultado\n",
    "\n",
    "# In[3.10]: Até o momento, foram extraídos 3 vetores: 'sensitividade',\n",
    "#'especificidade' e 'cutoffs'. Assim, criamos um dataframe que contém\n",
    "#os vetores mencionados\n",
    "\n",
    "dados_plotagem = espec_sens(observado = df_fidelidade_dummies['fidelidade'],\n",
    "                            predicts = df_fidelidade_dummies['phat'])\n",
    "dados_plotagem\n",
    "\n",
    "# In[3.11]: Plotagem de um gráfico que mostra a variação da especificidade e da\n",
    "#sensitividade em função do cutoff\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "with plt.style.context('seaborn-v0_8-whitegrid'):\n",
    "    plt.plot(dados_plotagem.cutoffs,dados_plotagem.sensitividade, marker='o',\n",
    "         color='indigo', markersize=8)\n",
    "    plt.plot(dados_plotagem.cutoffs,dados_plotagem.especificidade, marker='o',\n",
    "         color='limegreen', markersize=8)\n",
    "plt.xlabel('Cuttoff', fontsize=20)\n",
    "plt.ylabel('Sensitividade / Especificidade', fontsize=20)\n",
    "plt.xticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.yticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.legend(['Sensitividade', 'Especificidade'], fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# In[3.12]: Construção da curva ROC\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Função 'roc_curve' do pacote 'metrics' do sklearn\n",
    "\n",
    "fpr, tpr, thresholds =roc_curve(df_fidelidade_dummies['fidelidade'],\n",
    "                                df_fidelidade_dummies['phat'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Cálculo do coeficiente de GINI\n",
    "gini = (roc_auc - 0.5)/(0.5)\n",
    "\n",
    "# Plotando a curva ROC\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(fpr, tpr, marker='o', color='darkorchid', markersize=10, linewidth=3)\n",
    "plt.plot(fpr, fpr, color='gray', linestyle='dashed')\n",
    "plt.title('Área abaixo da curva: %g' % round(roc_auc, 4) +\n",
    "          ' | Coeficiente de GINI: %g' % round(gini, 4), fontsize=22)\n",
    "plt.xlabel('1 - Especificidade', fontsize=20)\n",
    "plt.ylabel('Sensitividade', fontsize=20)\n",
    "plt.xticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.yticks(np.arange(0, 1.1, 0.2), fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[EXEMPLO 4]:\n",
    "#############################################################################\n",
    "#                      REGRESSÃO LOGÍSTICA MULTINOMIAL                      #\n",
    "#                 EXEMPLO 4 - CARREGAMENTO DA BASE DE DADOS                 #\n",
    "#############################################################################\n",
    "\n",
    "df_atrasado_multinomial = pd.read_csv('atrasado_multinomial.csv',delimiter=',')\n",
    "df_atrasado_multinomial\n",
    "\n",
    "# Características das variáveis do dataset\n",
    "df_atrasado_multinomial.info()\n",
    "\n",
    "# Estatísticas univariadas\n",
    "df_atrasado_multinomial.describe()\n",
    "\n",
    "# In[4.1]: Note que a variável Y 'atrasado' está definida como objeto\n",
    "\n",
    "# Tabela de frequências absolutas da variável 'atrasado' com labels\n",
    "df_atrasado_multinomial['atrasado'].value_counts().sort_index()\n",
    "\n",
    "# Criando uma variável 'atrasado2' a partir da variável 'atrasado',\n",
    "#com labels iguais a 0, 1 e 2 e com tipo 'int' (poderia também ser do tipo\n",
    "#'float'), a fim de que seja possível estimar o modelo por meio\n",
    "#da função 'MNLogit' do pacote 'statsmodels.discrete.discrete_model'\n",
    "\n",
    "df_atrasado_multinomial.loc[df_atrasado_multinomial['atrasado']==\n",
    "                            'nao chegou atrasado',\n",
    "                            'atrasado2'] = 0 #categoria de referência\n",
    "\n",
    "df_atrasado_multinomial.loc[df_atrasado_multinomial['atrasado']==\n",
    "                            'chegou atrasado primeira aula',\n",
    "                            'atrasado2'] = 1\n",
    "\n",
    "df_atrasado_multinomial.loc[df_atrasado_multinomial['atrasado']==\n",
    "                            'chegou atrasado segunda aula',\n",
    "                            'atrasado2'] = 2\n",
    "\n",
    "# Definição do tipo 'int' para a variável dependente 'atrasado2'\n",
    "df_atrasado_multinomial['atrasado2'] =\\\n",
    "    df_atrasado_multinomial['atrasado2'].astype('int64')\n",
    "\n",
    "df_atrasado_multinomial.info()\n",
    "\n",
    "df_atrasado_multinomial\n",
    "\n",
    "# In[4.2]: Estimação do modelo logístico multinomial\n",
    "\n",
    "x = df_atrasado_multinomial.drop(columns=['estudante','atrasado','atrasado2'])\n",
    "y = df_atrasado_multinomial['atrasado2']\n",
    "\n",
    "# Esse pacote precisa que a constante seja definida pelo usuário\n",
    "X = sm.add_constant(x)\n",
    "\n",
    "# Estimação do modelo - função 'MNLogit' ('statsmodels.discrete.discrete_model')\n",
    "modelo_atrasado = MNLogit(endog=y, exog=X).fit()\n",
    "\n",
    "# Parâmetros do modelo 'modelo_atrasado'\n",
    "modelo_atrasado.summary()\n",
    "\n",
    "# In[4.3]: Vamos definir uma função 'Qui2' para se extrair a estatística geral\n",
    "# do modelo\n",
    "\n",
    "def Qui2(modelo_multinomial):\n",
    "    maximo = modelo_multinomial.llf\n",
    "    minimo = modelo_multinomial.llnull\n",
    "    qui2 = -2*(minimo - maximo)\n",
    "    pvalue = stats.distributions.chi2.sf(qui2,1)\n",
    "    df = pd.DataFrame({'Qui quadrado':[qui2],\n",
    "                       'pvalue':[pvalue]})\n",
    "    return df\n",
    "\n",
    "# In[4.4]: Estatística geral do 'modelo_atrasado'\n",
    "\n",
    "Qui2(modelo_atrasado)\n",
    "\n",
    "# In[4.5]: Fazendo predições para o 'modelo_atrasado'\n",
    "\n",
    "# Exemplo: qual a probabilidade média de atraso para cada categoria da\n",
    "#variável dependente, se o indivíduo tiver que percorrer 22km e passar\n",
    "#por 12 semáforos?\n",
    "\n",
    "# No nosso exemplo, temos os seguintes labels para a variável 'atrasado2':\n",
    "# 0: não chegou atrasado\n",
    "# 1: chegou atrasado primeira aula\n",
    "# 2: chegou atrasado segunda aula\n",
    "\n",
    "resultado = modelo_atrasado.predict(pd.DataFrame({'const':[1],\n",
    "                                                   'dist':[22],\n",
    "                                                   'sem':[12]})).round(4)\n",
    "\n",
    "resultado\n",
    "\n",
    "# Uma maneira de identificar a classe do resultado de acordo com o 'predict'\n",
    "resultado.idxmax(axis=1)\n",
    "\n",
    "# In[4.6]: Adicionando as probabilidades de ocorrência de cada uma das\n",
    "#categorias de Y definidas pela modelagem ao dataframe original, bem como a\n",
    "#respectiva classificação\n",
    "\n",
    "# Probabilidades de ocorrência das três categoriais\n",
    "# Definição do array 'phats':\n",
    "phats = modelo_atrasado.predict()\n",
    "phats\n",
    "\n",
    "# Transformação do array 'phats' para o dataframe 'phats':\n",
    "phats = pd.DataFrame(phats)\n",
    "phats\n",
    "\n",
    "# Concatenando o dataframe original com o dataframe 'phats':\n",
    "df_atrasado_multinomial = pd.concat([df_atrasado_multinomial, phats], axis=1)\n",
    "df_atrasado_multinomial\n",
    "\n",
    "# Analisando o resultado de acordo com a categoria de resposta:\n",
    "predicao = phats.idxmax(axis=1)\n",
    "predicao\n",
    "\n",
    "# Adicionando a categoria de resposta 'predicao' ao dataframe original,\n",
    "#por meio da criação da variável 'predicao'\n",
    "df_atrasado_multinomial['predicao'] = predicao\n",
    "df_atrasado_multinomial\n",
    "\n",
    "# Criando a variável 'predicao_label' a partir da variável 'predicao',\n",
    "#respeitando os seguintes rótulos:\n",
    "# 0: não chegou atrasado\n",
    "# 1: chegou atrasado primeira aula\n",
    "# 2: chegou atrasado segunda aula\n",
    "\n",
    "df_atrasado_multinomial.loc[df_atrasado_multinomial['predicao']==0,\n",
    "                            'predicao_label'] ='não chegou atrasado'\n",
    "df_atrasado_multinomial.loc[df_atrasado_multinomial['predicao']==1,\n",
    "                            'predicao_label'] ='chegou atrasado primeira aula'\n",
    "df_atrasado_multinomial.loc[df_atrasado_multinomial['predicao']==2,\n",
    "                            'predicao_label'] ='chegou atrasado segunda aula'\n",
    "\n",
    "df_atrasado_multinomial\n",
    "\n",
    "# In[4.7]: Criação de tabela para cálculo da eficiência global do modelo\n",
    "\n",
    "# Criando uma tabela para comparar as ocorrências reais com as predições\n",
    "table = pd.pivot_table(df_atrasado_multinomial,\n",
    "                       index=['predicao_label'],\n",
    "                       columns=['atrasado'],\n",
    "                       aggfunc='size')\n",
    "table\n",
    "\n",
    "# Substituindo 'NaN' por zero\n",
    "table = table.fillna(0)\n",
    "table\n",
    "\n",
    "# In[4.8]: Visualização, para fins didáticos, do objeto 'table' (dataframe)\n",
    "#no ambiente Plots\n",
    "\n",
    "from tabulate import tabulate\n",
    "tabela = tabulate(table, headers='keys', tablefmt='grid', numalign='center')\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.text(0.1, 0.1, tabela, {'family': 'monospace', 'size': 15})\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# In[4.9]: Eficiência global do modelo propriamente dita\n",
    "\n",
    "# Transformando o dataframe 'table' para 'array', para que seja possível\n",
    "#estabelecer o atributo 'diagonal'\n",
    "table = table.to_numpy()\n",
    "table\n",
    "\n",
    "# Eficiência global do modelo\n",
    "acuracia = table.diagonal().sum()/table.sum()\n",
    "acuracia\n",
    "\n",
    "# In[4.10]: Plotagens das probabilidades\n",
    "\n",
    "# Plotagem das smooth probability lines para a variável 'dist'\n",
    "\n",
    "# 0: não chegou atrasado\n",
    "# 1: chegou atrasado primeira aula\n",
    "# 2: chegou atrasado segunda aula\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "# Plot para \"não chegou atrasado\"\n",
    "sns.regplot(x='dist', y=df_atrasado_multinomial[0],\n",
    "            data=df_atrasado_multinomial, ci=False, order=4,\n",
    "            line_kws={'color':'indigo', 'linewidth':4,\n",
    "                      'label':'não chegou atrasado'},\n",
    "            scatter_kws={'color':'indigo', 's':80, 'alpha':0.5})\n",
    "\n",
    "# Plot para \"chegou atrasado na primeira aula\"\n",
    "sns.regplot(x='dist', y=df_atrasado_multinomial[1],\n",
    "            data=df_atrasado_multinomial, ci=None, order=4,\n",
    "            line_kws={'color':'darkgreen', 'linewidth':4,\n",
    "                      'label':'chegou atrasado na primeira aula'},\n",
    "            scatter_kws={'color':'darkgreen', 's':80, 'alpha':0.5})\n",
    "\n",
    "# Plot para \"chegou atrasado na segunda aula\"\n",
    "sns.regplot(x='dist', y=df_atrasado_multinomial[2],\n",
    "            data=df_atrasado_multinomial, ci=None, order=4,\n",
    "            line_kws={'color':'darkorange', 'linewidth':4,\n",
    "                      'label':'chegou atrasado na segunda aula'},\n",
    "            scatter_kws={'color':'darkorange', 's':80, 'alpha':0.5})\n",
    "\n",
    "plt.xlabel('Distância Percorrida', fontsize=18)\n",
    "plt.ylabel('Probabilidades', fontsize=18)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(loc='center left', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# In[4.11]: Plotagens das probabilidades\n",
    "\n",
    "# Plotagem das smooth probability lines para a variável 'sem'\n",
    "\n",
    "# 0: não chegou atrasado\n",
    "# 1: chegou atrasado primeira aula\n",
    "# 2: chegou atrasado segunda aula\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "# Plot para \"não chegou atrasado\"\n",
    "sns.regplot(x='sem', y=df_atrasado_multinomial[0],\n",
    "            data=df_atrasado_multinomial, ci=None, order=4,\n",
    "            line_kws={'color':'indigo', 'linewidth':4,\n",
    "                      'label':'não chegou atrasado'},\n",
    "            scatter_kws={'color':'indigo', 's':80, 'alpha':0.5})\n",
    "\n",
    "# Plot para \"chegou atrasado na primeira aula\"\n",
    "sns.regplot(x='sem', y=df_atrasado_multinomial[1],\n",
    "            data=df_atrasado_multinomial, ci=None, order=4,\n",
    "            line_kws={'color':'darkgreen', 'linewidth':4,\n",
    "                      'label':'chegou atrasado na primeira aula'},\n",
    "            scatter_kws={'color':'darkgreen', 's':80, 'alpha':0.5})\n",
    "\n",
    "# Plot para \"chegou atrasado na segunda aula\"\n",
    "sns.regplot(x='sem', y=df_atrasado_multinomial[2],\n",
    "            data=df_atrasado_multinomial, ci=None, order=4,\n",
    "            line_kws={'color':'darkorange', 'linewidth':4,\n",
    "                      'label':'chegou atrasado na segunda aula'},\n",
    "            scatter_kws={'color':'darkorange', 's':80, 'alpha':0.5})\n",
    "\n",
    "plt.xlabel('Quantidade de Semáforos', fontsize=18)\n",
    "plt.ylabel('Probabilidades', fontsize=18)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(loc='upper center', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# In[4.12]: Plotagem tridimensional para cada probabilidade de ocorrência de\n",
    "#cada categoria da variável dependente\n",
    "\n",
    "# Probabilidades de não se chegar atrasado (função 'go' do pacote 'plotly')\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "trace = go.Mesh3d(\n",
    "    x=df_atrasado_multinomial['dist'], \n",
    "    y=df_atrasado_multinomial['sem'],\n",
    "    z=df_atrasado_multinomial[0],\n",
    "    opacity=1, intensity=df_atrasado_multinomial[0],\n",
    "    colorscale=\"Viridis\")\n",
    "\n",
    "layout = go.Layout(\n",
    "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
    "    width=800,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "plot_figure = go.Figure(data=data, layout=layout)\n",
    "\n",
    "plot_figure.update_layout(scene = dict(\n",
    "                        xaxis_title='dist',\n",
    "                        yaxis_title='sem',\n",
    "                        zaxis_title='não chegou atrasado'))\n",
    "\n",
    "plot_figure.show()\n",
    "\n",
    "# In[4.13]: Plotagem tridimensional para cada probabilidade de ocorrência de\n",
    "#cada categoria da variável dependente\n",
    "\n",
    "# Probabilidades de se chegar atrasado à primeira aula (função 'go' do pacote\n",
    "#'plotly')\n",
    "\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "trace = go.Mesh3d(\n",
    "    x=df_atrasado_multinomial['dist'], \n",
    "    y=df_atrasado_multinomial['sem'],\n",
    "    z=df_atrasado_multinomial[1],\n",
    "    opacity=1, intensity=df_atrasado_multinomial[1],\n",
    "    colorscale=\"Viridis\")\n",
    "\n",
    "layout = go.Layout(\n",
    "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
    "    width=800,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "plot_figure = go.Figure(data=data, layout=layout)\n",
    "\n",
    "plot_figure.update_layout(scene = dict(\n",
    "                        xaxis_title='dist',\n",
    "                        yaxis_title='sem',\n",
    "                        zaxis_title='chegou atrasado à primeira aula'))\n",
    "\n",
    "plot_figure.show()\n",
    "\n",
    "# In[4.14]: Plotagem tridimensional para cada probabilidade de ocorrência de\n",
    "#cada categoria da variável dependente\n",
    "\n",
    "# Probabilidades de se chegar atrasado à segunda aula (função 'go' do pacote\n",
    "#'plotly')\n",
    "\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "trace = go.Mesh3d(\n",
    "    x=df_atrasado_multinomial['dist'], \n",
    "    y=df_atrasado_multinomial['sem'],\n",
    "    z=df_atrasado_multinomial[2],\n",
    "    opacity=1, intensity=df_atrasado_multinomial[2],\n",
    "    colorscale=\"Viridis\")\n",
    "\n",
    "layout = go.Layout(\n",
    "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
    "    width=800,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "plot_figure = go.Figure(data=data, layout=layout)\n",
    "\n",
    "plot_figure.update_layout(scene = dict(\n",
    "                        xaxis_title='dist',\n",
    "                        yaxis_title='sem',\n",
    "                        zaxis_title='chegou atrasado à segunda aula'))\n",
    "\n",
    "plot_figure.show()\n",
    "\n",
    "# In[4.15]: Visualização das sigmoides tridimensionais em um único gráfico\n",
    "\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "trace = go.Mesh3d(\n",
    "    x=df_atrasado_multinomial['dist'], \n",
    "    y=df_atrasado_multinomial['sem'],\n",
    "    z=df_atrasado_multinomial[0],\n",
    "    opacity=1,\n",
    "    color='indigo')\n",
    "\n",
    "layout = go.Layout(\n",
    "    margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
    "    width=800,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "plot_figure = go.Figure(data=data, layout=layout)\n",
    "\n",
    "trace_1 = go.Mesh3d(\n",
    "            x=df_atrasado_multinomial['dist'], \n",
    "            y=df_atrasado_multinomial['sem'],\n",
    "            z=df_atrasado_multinomial[1],\n",
    "            opacity=1,\n",
    "            color='darkgreen')\n",
    "\n",
    "plot_figure.add_trace(trace_1)\n",
    "\n",
    "trace_2 = go.Mesh3d(\n",
    "            x=df_atrasado_multinomial['dist'], \n",
    "            y=df_atrasado_multinomial['sem'],\n",
    "            z=df_atrasado_multinomial[2],\n",
    "            opacity=1,\n",
    "            color='darkorange')\n",
    "\n",
    "\n",
    "plot_figure.add_trace(trace_2)\n",
    "\n",
    "plot_figure.update_layout(\n",
    "    template='plotly_dark',\n",
    "    scene = dict(\n",
    "        xaxis_title='dist',\n",
    "        yaxis_title='sem',\n",
    "        zaxis_title='probabilidades')\n",
    "    )\n",
    "\n",
    "plot_figure.show()\n",
    "\n",
    "################################## FIM ######################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
